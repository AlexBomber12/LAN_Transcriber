diff --git a/lan_app/db.py b/lan_app/db.py
index e03b0fb..d0ceaa0 100644
--- a/lan_app/db.py
+++ b/lan_app/db.py
@@ -117,8 +117,13 @@ _MIGRATIONS: tuple[str, ...] = (
     CREATE INDEX IF NOT EXISTS idx_jobs_status ON jobs(status);
     CREATE INDEX IF NOT EXISTS idx_jobs_created_at ON jobs(created_at DESC);
     """,
+    """
+    ALTER TABLE recordings ADD COLUMN target_summary_language TEXT;
+    """,
 )
 
+_UNSET = object()
+
 
 def _utc_now() -> str:
     return datetime.now(tz=timezone.utc).replace(microsecond=0).isoformat().replace(
@@ -196,6 +201,7 @@ def create_recording(
     quarantine_reason: str | None = None,
     language_auto: str | None = None,
     language_override: str | None = None,
+    target_summary_language: str | None = None,
     project_id: int | None = None,
     onenote_page_id: str | None = None,
     drive_file_id: str | None = None,
@@ -210,10 +216,10 @@ def create_recording(
             """
             INSERT INTO recordings (
                 id, source, source_filename, captured_at, duration_sec, status,
-                quarantine_reason, language_auto, language_override, project_id,
+                quarantine_reason, language_auto, language_override, target_summary_language, project_id,
                 onenote_page_id, drive_file_id, drive_md5, created_at, updated_at
             )
-            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
+            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
             """,
             (
                 recording_id,
@@ -225,6 +231,7 @@ def create_recording(
                 quarantine_reason,
                 language_auto,
                 language_override,
+                target_summary_language,
                 project_id,
                 onenote_page_id,
                 drive_file_id,
@@ -322,6 +329,49 @@ def set_recording_status(
     return updated.rowcount > 0
 
 
+def set_recording_language_settings(
+    recording_id: str,
+    *,
+    settings: AppSettings | None = None,
+    language_auto: str | None | object = _UNSET,
+    transcript_language_override: str | None | object = _UNSET,
+    target_summary_language: str | None | object = _UNSET,
+) -> bool:
+    init_db(settings)
+    now = _utc_now()
+    updates: list[str] = []
+    params: list[Any] = []
+
+    if language_auto is not _UNSET:
+        updates.append("language_auto = ?")
+        params.append(language_auto)
+    if transcript_language_override is not _UNSET:
+        updates.append("language_override = ?")
+        params.append(transcript_language_override)
+    if target_summary_language is not _UNSET:
+        updates.append("target_summary_language = ?")
+        params.append(target_summary_language)
+
+    if not updates:
+        return False
+
+    updates.append("updated_at = ?")
+    params.append(now)
+    params.append(recording_id)
+
+    with connect(settings) as conn:
+        updated = conn.execute(
+            f"""
+            UPDATE recordings
+            SET {", ".join(updates)}
+            WHERE id = ?
+            """,
+            params,
+        )
+        conn.commit()
+    return updated.rowcount > 0
+
+
 def delete_recording(
     recording_id: str,
     *,
@@ -703,6 +753,7 @@ __all__ = [
     "get_recording",
     "list_recordings",
     "set_recording_status",
+    "set_recording_language_settings",
     "delete_recording",
     "create_job",
     "get_job",
diff --git a/lan_app/templates/recording_detail.html b/lan_app/templates/recording_detail.html
index ec11e81..22be248 100644
--- a/lan_app/templates/recording_detail.html
+++ b/lan_app/templates/recording_detail.html
@@ -34,7 +34,8 @@
     <span class="k">Duration</span><span class="v">{% if rec.duration_sec %}{{ rec.duration_sec }}s{% else %}—{% endif %}</span>
     <span class="k">Project ID</span><span class="v">{{ rec.project_id or '—' }}</span>
     <span class="k">Language (auto)</span><span class="v">{{ rec.language_auto or '—' }}</span>
-    <span class="k">Language (override)</span><span class="v">{{ rec.language_override or '—' }}</span>
+    <span class="k">Transcript language override</span><span class="v">{{ rec.language_override or '—' }}</span>
+    <span class="k">Target summary language</span><span class="v">{{ rec.target_summary_language or '—' }}</span>
     <span class="k">Drive file ID</span><span class="v">{{ rec.drive_file_id or '—' }}</span>
     <span class="k">OneNote page ID</span><span class="v">{{ rec.onenote_page_id or '—' }}</span>
     <span class="k">Quarantine reason</span><span class="v">{{ rec.quarantine_reason or '—' }}</span>
@@ -127,7 +128,107 @@
   <p class="placeholder">Speaker assignments — available after PR-VOICE-01.</p>
 
 {% elif current_tab == 'language' %}
-  <p class="placeholder">Language spans — available after PR-LANG-01.</p>
+  {% set lang = language or {} %}
+
+  <h2>Detected Languages</h2>
+  <div class="info-grid">
+    <span class="k">Detected language</span><span class="v">{{ lang.detected_label or '—' }}</span>
+    <span class="k">Dominant language</span><span class="v">{{ lang.dominant_label or '—' }}</span>
+    <span class="k">Mixed-language meeting</span><span class="v">{{ 'Yes' if lang.is_mixed else 'No' }}</span>
+    <span class="k">Current summary target</span><span class="v">{{ lang.target_summary_language_label or '—' }}</span>
+    <span class="k">Transcript override</span><span class="v">{{ lang.transcript_language_override_label or '—' }}</span>
+  </div>
+
+  <h2>Language Distribution</h2>
+  {% if lang.distribution %}
+  <table>
+    <thead>
+      <tr>
+        <th>Language</th>
+        <th>Share (%)</th>
+      </tr>
+    </thead>
+    <tbody>
+      {% for row in lang.distribution %}
+      <tr>
+        <td>{{ row.label }}</td>
+        <td>{{ '%.2f'|format(row.percent) }}</td>
+      </tr>
+      {% endfor %}
+    </tbody>
+  </table>
+  {% else %}
+  <p class="placeholder">No language distribution available yet.</p>
+  {% endif %}
+
+  <h2>Language Spans</h2>
+  {% if lang.spans %}
+  <table>
+    <thead>
+      <tr>
+        <th>Start</th>
+        <th>End</th>
+        <th>Language</th>
+      </tr>
+    </thead>
+    <tbody>
+      {% for span in lang.spans %}
+      <tr>
+        <td>{{ '%.3f'|format(span.start) }}</td>
+        <td>{{ '%.3f'|format(span.end) }}</td>
+        <td>{{ span.label }}</td>
+      </tr>
+      {% endfor %}
+    </tbody>
+  </table>
+  {% else %}
+  <p class="placeholder">No language spans available yet.</p>
+  {% endif %}
+
+  <h2>Overrides and Reprocess</h2>
+  <form method="post" action="/ui/recordings/{{ rec.id }}/language/settings">
+    <div class="form-row">
+      <label for="target_summary_language">target_summary_language</label>
+      <select id="target_summary_language" name="target_summary_language">
+        <option value="">Auto (dominant language)</option>
+        {% for opt in lang.options or [] %}
+        <option value="{{ opt.code }}" {% if lang.target_summary_language == opt.code %}selected{% endif %}>{{ opt.label }}</option>
+        {% endfor %}
+      </select>
+    </div>
+    <div class="form-row">
+      <label for="transcript_language_override">transcript_language_override</label>
+      <select id="transcript_language_override" name="transcript_language_override">
+        <option value="">None (auto detect)</option>
+        {% for opt in lang.options or [] %}
+        <option value="{{ opt.code }}" {% if lang.transcript_language_override == opt.code %}selected{% endif %}>{{ opt.label }}</option>
+        {% endfor %}
+      </select>
+    </div>
+    <div class="filters" style="margin-top:8px">
+      <button type="submit" class="btn">Save overrides</button>
+      <button
+        type="submit"
+        class="btn"
+        formaction="/ui/recordings/{{ rec.id }}/language/resummarize"
+      >
+        Re-summarize (LLM only)
+      </button>
+      <button
+        type="submit"
+        class="btn btn-danger"
+        formaction="/ui/recordings/{{ rec.id }}/language/retranscribe"
+        onclick="return confirm('Re-transcribe reruns STT and diarization. Continue?')"
+      >
+        Re-transcribe (STT again)
+      </button>
+    </div>
+  </form>
+
+  {% if lang.summary_preview %}
+  <h2>Latest Summary</h2>
+  <pre style="white-space:pre-wrap;background:#f8f9ff;border:1px solid #ccd;padding:8px;font:12px/1.4 'Courier New',monospace;max-height:240px;overflow:auto">{{ lang.summary_preview }}</pre>
+  {% endif %}
 
 {% elif current_tab == 'metrics' %}
   <p class="placeholder">Meeting metrics — available after PR-METRICS-01.</p>
diff --git a/lan_app/ui_routes.py b/lan_app/ui_routes.py
index 51c041b..71295d9 100644
--- a/lan_app/ui_routes.py
+++ b/lan_app/ui_routes.py
@@ -5,6 +5,8 @@ Uses Jinja2 templates + HTMX (bundled locally) for a minimal, DB-window-style UI
 
 from __future__ import annotations
 
+import asyncio
+import json
 import shutil
 import sqlite3
 from pathlib import Path
@@ -23,6 +25,7 @@ from .calendar import (
 from .config import AppSettings
 from .constants import (
     JOB_STATUSES,
+    JOB_TYPE_PRECHECK,
     RECORDING_STATUSES,
     RECORDING_STATUS_QUARANTINE,
 )
@@ -36,10 +39,15 @@ from .db import (
     list_projects,
     list_recordings,
     list_voice_profiles,
+    set_recording_language_settings,
     set_recording_status,
 )
 from .jobs import enqueue_recording_job, purge_pending_recording_jobs
 from .ms_graph import GraphAuthError, ms_connection_state
+from lan_transcriber.artifacts import atomic_write_json
+from lan_transcriber.llm_client import LLMClient
+from lan_transcriber.pipeline import Settings as PipelineSettings
+from lan_transcriber.pipeline import build_summary_prompts
 
 _TEMPLATES_DIR = Path(__file__).parent / "templates"
 _STATIC_DIR = Path(__file__).parent / "static"
@@ -48,6 +56,286 @@ templates = Jinja2Templates(directory=str(_TEMPLATES_DIR))
 ui_router = APIRouter()
 _settings = AppSettings()
 
+_LANGUAGE_NAME_MAP: dict[str, str] = {
+    "ar": "Arabic",
+    "de": "German",
+    "en": "English",
+    "es": "Spanish",
+    "fr": "French",
+    "hi": "Hindi",
+    "it": "Italian",
+    "ja": "Japanese",
+    "ko": "Korean",
+    "nl": "Dutch",
+    "pl": "Polish",
+    "pt": "Portuguese",
+    "ru": "Russian",
+    "tr": "Turkish",
+    "uk": "Ukrainian",
+    "zh": "Chinese",
+}
+
+_LANGUAGE_CODE_MAP: dict[str, str] = {
+    "eng": "en",
+    "spa": "es",
+    "fra": "fr",
+    "fre": "fr",
+    "deu": "de",
+    "ger": "de",
+    "ita": "it",
+    "por": "pt",
+    "rus": "ru",
+    "ukr": "uk",
+    "jpn": "ja",
+    "kor": "ko",
+    "zho": "zh",
+    "chi": "zh",
+}
+
+_COMMON_LANGUAGE_CODES = ("en", "es", "fr", "de", "pt", "it", "zh", "ja", "ko", "ru")
+
+
+def _normalise_language_code(value: object | None) -> str | None:
+    if not isinstance(value, str):
+        return None
+    raw = value.strip().lower()
+    if not raw:
+        return None
+    token = raw.replace("_", "-").split("-", 1)[0]
+    if len(token) == 2 and token.isalpha():
+        return token
+    if len(token) == 3 and token.isalpha():
+        return _LANGUAGE_CODE_MAP.get(token, None)
+    return None
+
+
+def _language_display_name(code: str | None) -> str:
+    if not code:
+        return "—"
+    if code == "unknown":
+        return "Unknown"
+    return f"{_LANGUAGE_NAME_MAP.get(code, code.upper())} ({code})"
+
+
+def _parse_language_form_value(value: str, *, field_name: str) -> str | None:
+    stripped = value.strip()
+    if not stripped:
+        return None
+    parsed = _normalise_language_code(stripped)
+    if parsed is None:
+        raise ValueError(f"{field_name} must be a language code such as en or es")
+    return parsed
+
+
+def _load_json_dict(path: Path) -> dict[str, Any]:
+    if not path.exists():
+        return {}
+    try:
+        payload = json.loads(path.read_text(encoding="utf-8"))
+    except (OSError, ValueError):
+        return {}
+    if not isinstance(payload, dict):
+        return {}
+    return payload
+
+
+def _recording_derived_paths(recording_id: str, settings: AppSettings) -> tuple[Path, Path]:
+    derived = settings.recordings_root / recording_id / "derived"
+    return derived / "transcript.json", derived / "summary.json"
+
+
+def _sync_transcript_language_settings(
+    recording_id: str,
+    *,
+    settings: AppSettings,
+    target_summary_language: str | None,
+    transcript_language_override: str | None,
+) -> None:
+    transcript_path, _summary_path = _recording_derived_paths(recording_id, settings)
+    payload = _load_json_dict(transcript_path)
+    if not payload:
+        return
+    payload["target_summary_language"] = target_summary_language
+    payload["transcript_language_override"] = transcript_language_override
+    atomic_write_json(transcript_path, payload)
+
+
+def _language_options(
+    *,
+    distribution_codes: list[str],
+    target_summary_language: str | None,
+    transcript_language_override: str | None,
+) -> list[dict[str, str]]:
+    ordered: list[str] = []
+    seen: set[str] = set()
+    for code in distribution_codes:
+        if code == "unknown":
+            continue
+        if code not in seen:
+            ordered.append(code)
+            seen.add(code)
+    for code in (target_summary_language, transcript_language_override):
+        if code and code not in seen:
+            ordered.append(code)
+            seen.add(code)
+    for code in _COMMON_LANGUAGE_CODES:
+        if code not in seen:
+            ordered.append(code)
+            seen.add(code)
+    return [
+        {"code": code, "label": _language_display_name(code)}
+        for code in ordered
+    ]
+
+
+def _language_tab_context(recording_id: str, rec: dict[str, Any], settings: AppSettings) -> dict[str, Any]:
+    transcript_path, summary_path = _recording_derived_paths(recording_id, settings)
+    transcript_payload = _load_json_dict(transcript_path)
+    summary_payload = _load_json_dict(summary_path)
+
+    language_payload = transcript_payload.get("language")
+    language_obj = language_payload if isinstance(language_payload, dict) else {}
+    detected = _normalise_language_code(language_obj.get("detected")) or _normalise_language_code(
+        rec.get("language_auto")
+    )
+    dominant = _normalise_language_code(transcript_payload.get("dominant_language")) or detected
+
+    distribution_payload = transcript_payload.get("language_distribution")
+    distribution_obj = distribution_payload if isinstance(distribution_payload, dict) else {}
+    distribution_rows: list[dict[str, Any]] = []
+    for code_raw, pct_raw in distribution_obj.items():
+        code = _normalise_language_code(code_raw) or str(code_raw)
+        try:
+            percent = float(pct_raw)
+        except (TypeError, ValueError):
+            continue
+        distribution_rows.append(
+            {
+                "code": code,
+                "label": _language_display_name(code),
+                "percent": round(percent, 2),
+            }
+        )
+    distribution_rows.sort(key=lambda row: (-row["percent"], row["code"]))
+
+    spans_payload = transcript_payload.get("language_spans")
+    spans_raw = spans_payload if isinstance(spans_payload, list) else []
+    span_rows: list[dict[str, Any]] = []
+    for row in spans_raw:
+        if not isinstance(row, dict):
+            continue
+        try:
+            start = float(row.get("start", 0.0))
+            end = float(row.get("end", start))
+        except (TypeError, ValueError):
+            continue
+        code = _normalise_language_code(row.get("lang")) or str(row.get("lang") or "unknown")
+        span_rows.append(
+            {
+                "start": round(start, 3),
+                "end": round(max(end, start), 3),
+                "code": code,
+                "label": _language_display_name(code),
+            }
+        )
+    span_rows.sort(key=lambda row: (row["start"], row["end"]))
+
+    target_summary_language = _normalise_language_code(
+        rec.get("target_summary_language")
+    ) or _normalise_language_code(
+        transcript_payload.get("target_summary_language")
+    ) or dominant
+    transcript_language_override = _normalise_language_code(
+        rec.get("language_override")
+    ) or _normalise_language_code(
+        transcript_payload.get("transcript_language_override")
+    )
+
+    distribution_codes = [str(row["code"]) for row in distribution_rows]
+    non_unknown_distribution = [code for code in distribution_codes if code != "unknown"]
+
+    return {
+        "detected": detected,
+        "detected_label": _language_display_name(detected),
+        "dominant": dominant,
+        "dominant_label": _language_display_name(dominant),
+        "distribution": distribution_rows,
+        "spans": span_rows,
+        "is_mixed": len(set(non_unknown_distribution)) >= 2,
+        "target_summary_language": target_summary_language or "",
+        "target_summary_language_label": _language_display_name(target_summary_language),
+        "transcript_language_override": transcript_language_override or "",
+        "transcript_language_override_label": _language_display_name(transcript_language_override),
+        "summary_preview": str(summary_payload.get("summary") or "").strip(),
+        "summary_model": str(summary_payload.get("model") or ""),
+        "options": _language_options(
+            distribution_codes=distribution_codes,
+            target_summary_language=target_summary_language,
+            transcript_language_override=transcript_language_override,
+        ),
+    }
+
+
+def _resummarize_recording(
+    recording_id: str,
+    *,
+    settings: AppSettings,
+    target_summary_language: str | None,
+) -> None:
+    transcript_path, summary_path = _recording_derived_paths(recording_id, settings)
+    transcript_payload = _load_json_dict(transcript_path)
+    if not transcript_payload:
+        raise ValueError("No transcript.json found for this recording")
+
+    transcript_text = str(transcript_payload.get("text") or "").strip()
+    if not transcript_text:
+        raise ValueError("Transcript text is empty; re-transcribe first")
+
+    language_payload = transcript_payload.get("language")
+    language_obj = language_payload if isinstance(language_payload, dict) else {}
+    resolved_target = (
+        target_summary_language
+        or _normalise_language_code(transcript_payload.get("target_summary_language"))
+        or _normalise_language_code(transcript_payload.get("dominant_language"))
+        or _normalise_language_code(language_obj.get("detected"))
+        or "en"
+    )
+    pipeline_settings = PipelineSettings(
+        recordings_root=settings.recordings_root,
+        voices_dir=settings.data_root / "voices",
+        unknown_dir=settings.recordings_root / "unknown",
+        tmp_root=settings.data_root / "tmp",
+    )
+    system_prompt, user_prompt = build_summary_prompts(
+        transcript_text,
+        resolved_target,
+    )
+    message = asyncio.run(
+        LLMClient().generate(
+            system_prompt=system_prompt,
+            user_prompt=user_prompt,
+            model=pipeline_settings.llm_model,
+        )
+    )
+    summary_text = message.get("content", "") if isinstance(message, dict) else str(message)
+
+    summary_payload = _load_json_dict(summary_path)
+    friendly = summary_payload.get("friendly")
+    if not isinstance(friendly, int):
+        friendly = 0
+    summary_payload.update(
+        {
+            "friendly": friendly,
+            "model": pipeline_settings.llm_model,
+            "summary": summary_text,
+            "target_summary_language": resolved_target,
+        }
+    )
+    atomic_write_json(summary_path, summary_payload)
+
+    transcript_payload["target_summary_language"] = resolved_target
+    atomic_write_json(transcript_path, transcript_payload)
+
 
 def _status_counts(settings: AppSettings) -> dict[str, int]:
     counts: dict[str, int] = {}
@@ -138,6 +426,7 @@ async def ui_recording_detail(
     tabs = ["overview", "calendar", "project", "speakers", "language", "metrics", "log"]
     current_tab = tab if tab in tabs else "overview"
     calendar: dict[str, Any] | None = None
+    language: dict[str, Any] | None = None
     if current_tab == "calendar":
         try:
             calendar = await run_in_threadpool(
@@ -152,6 +441,8 @@ async def ui_recording_detail(
                 settings=_settings,
             )
             calendar["fetch_error"] = str(exc)
+    if current_tab == "language":
+        language = _language_tab_context(recording_id, rec, _settings)
 
     return templates.TemplateResponse(
         request,
@@ -163,6 +454,7 @@ async def ui_recording_detail(
             "tabs": tabs,
             "current_tab": current_tab,
             "calendar": calendar,
+            "language": language,
         },
     )
 
@@ -348,6 +640,107 @@ async def ui_action_delete(recording_id: str) -> Any:
     return resp
 
 
+def _save_language_settings(
+    recording_id: str,
+    *,
+    target_summary_language: str,
+    transcript_language_override: str,
+) -> tuple[str | None, str | None]:
+    target = _parse_language_form_value(
+        target_summary_language,
+        field_name="target_summary_language",
+    )
+    transcript_override = _parse_language_form_value(
+        transcript_language_override,
+        field_name="transcript_language_override",
+    )
+    set_recording_language_settings(
+        recording_id,
+        settings=_settings,
+        target_summary_language=target,
+        transcript_language_override=transcript_override,
+    )
+    _sync_transcript_language_settings(
+        recording_id,
+        settings=_settings,
+        target_summary_language=target,
+        transcript_language_override=transcript_override,
+    )
+    return target, transcript_override
+
+
+@ui_router.post("/ui/recordings/{recording_id}/language/settings")
+async def ui_save_language_settings(
+    recording_id: str,
+    target_summary_language: str = Form(default=""),
+    transcript_language_override: str = Form(default=""),
+) -> Any:
+    if get_recording(recording_id, settings=_settings) is None:
+        return HTMLResponse("Not found", status_code=404)
+    try:
+        _save_language_settings(
+            recording_id,
+            target_summary_language=target_summary_language,
+            transcript_language_override=transcript_language_override,
+        )
+    except ValueError as exc:
+        return HTMLResponse(str(exc), status_code=422)
+    return RedirectResponse(f"/recordings/{recording_id}?tab=language", status_code=303)
+
+
+@ui_router.post("/ui/recordings/{recording_id}/language/resummarize")
+async def ui_resummarize_language(
+    recording_id: str,
+    target_summary_language: str = Form(default=""),
+    transcript_language_override: str = Form(default=""),
+) -> Any:
+    if get_recording(recording_id, settings=_settings) is None:
+        return HTMLResponse("Not found", status_code=404)
+    try:
+        target, _transcript_override = _save_language_settings(
+            recording_id,
+            target_summary_language=target_summary_language,
+            transcript_language_override=transcript_language_override,
+        )
+        await run_in_threadpool(
+            _resummarize_recording,
+            recording_id,
+            settings=_settings,
+            target_summary_language=target,
+        )
+    except ValueError as exc:
+        return HTMLResponse(str(exc), status_code=422)
+    except Exception as exc:
+        return HTMLResponse(f"Re-summarize failed: {exc}", status_code=503)
+    return RedirectResponse(f"/recordings/{recording_id}?tab=language", status_code=303)
+
+
+@ui_router.post("/ui/recordings/{recording_id}/language/retranscribe")
+async def ui_retranscribe_language(
+    recording_id: str,
+    target_summary_language: str = Form(default=""),
+    transcript_language_override: str = Form(default=""),
+) -> Any:
+    if get_recording(recording_id, settings=_settings) is None:
+        return HTMLResponse("Not found", status_code=404)
+    try:
+        _save_language_settings(
+            recording_id,
+            target_summary_language=target_summary_language,
+            transcript_language_override=transcript_language_override,
+        )
+        enqueue_recording_job(
+            recording_id,
+            job_type=JOB_TYPE_PRECHECK,
+            settings=_settings,
+        )
+    except ValueError as exc:
+        return HTMLResponse(str(exc), status_code=422)
+    except Exception as exc:
+        return HTMLResponse(f"Re-transcribe failed: {exc}", status_code=503)
+    return RedirectResponse(f"/recordings/{recording_id}?tab=log", status_code=303)
+
+
 @ui_router.post("/ui/recordings/{recording_id}/calendar/select")
 async def ui_select_calendar(recording_id: str, event_id: str = Form(default="")) -> Any:
     if get_recording(recording_id, settings=_settings) is None:
diff --git a/lan_app/worker_tasks.py b/lan_app/worker_tasks.py
index c251bf1..5e45d04 100644
--- a/lan_app/worker_tasks.py
+++ b/lan_app/worker_tasks.py
@@ -2,6 +2,7 @@ from __future__ import annotations
 
 import asyncio
 from datetime import datetime, timezone
+import json
 from pathlib import Path
 from types import SimpleNamespace
 from typing import Any
@@ -22,7 +23,15 @@ from .constants import (
     RECORDING_STATUS_QUARANTINE,
     RECORDING_STATUS_READY,
 )
-from .db import fail_job, finish_job, init_db, set_recording_status, start_job
+from .db import (
+    fail_job,
+    finish_job,
+    get_recording,
+    init_db,
+    set_recording_language_settings,
+    set_recording_status,
+    start_job,
+)
 
 
 def _utc_now() -> str:
@@ -81,6 +90,29 @@ def _resolve_raw_audio_path(recording_id: str, settings: AppSettings) -> Path |
     return candidates[0]
 
 
+def _clean_language_value(value: object | None) -> str | None:
+    if not isinstance(value, str):
+        return None
+    cleaned = value.strip()
+    return cleaned or None
+
+
+def _load_transcript_language_payload(
+    recording_id: str,
+    settings: AppSettings,
+) -> tuple[str | None, str | None]:
+    transcript_path = settings.recordings_root / recording_id / "derived" / "transcript.json"
+    if not transcript_path.exists():
+        return None, None
+    try:
+        payload = json.loads(transcript_path.read_text(encoding="utf-8"))
+    except (OSError, ValueError):
+        return None, None
+    dominant = _clean_language_value(payload.get("dominant_language"))
+    target = _clean_language_value(payload.get("target_summary_language"))
+    return dominant, target
+
+
 class _FallbackDiariser:
     def __init__(self, duration_sec: float | None) -> None:
         self._duration_sec = max(duration_sec or 0.1, 0.1)
@@ -139,6 +171,10 @@ def _run_precheck_pipeline(
     settings: AppSettings,
     log_path: Path,
 ) -> tuple[str, str | None]:
+    recording = get_recording(recording_id, settings=settings) or {}
+    transcript_language_override = _clean_language_value(recording.get("language_override"))
+    target_summary_language = _clean_language_value(recording.get("target_summary_language"))
+
     audio_path = _resolve_raw_audio_path(recording_id, settings)
     if audio_path is None:
         _append_step_log(log_path, "precheck skipped: raw audio not found")
@@ -166,8 +202,25 @@ def _run_precheck_pipeline(
             diariser=diariser,
             recording_id=recording_id,
             precheck=precheck,
+            target_summary_language=target_summary_language,
+            transcript_language_override=transcript_language_override,
         )
     )
+    dominant_language, resolved_target_language = _load_transcript_language_payload(
+        recording_id,
+        settings,
+    )
+    update_payload: dict[str, str] = {}
+    if dominant_language:
+        update_payload["language_auto"] = dominant_language
+    if resolved_target_language:
+        update_payload["target_summary_language"] = resolved_target_language
+    if update_payload:
+        set_recording_language_settings(
+            recording_id,
+            settings=settings,
+            **update_payload,
+        )
     _append_step_log(log_path, "pipeline artifacts generated")
     if precheck.quarantine_reason:
         _append_step_log(
diff --git a/lan_transcriber/pipeline.py b/lan_transcriber/pipeline.py
index 20accea..1225395 100644
--- a/lan_transcriber/pipeline.py
+++ b/lan_transcriber/pipeline.py
@@ -2,6 +2,7 @@ from __future__ import annotations
 
 import asyncio
 import audioop
+import re
 import shutil
 import subprocess
 import time
@@ -155,13 +156,251 @@ def _normalise_asr_segments(raw_segments: Sequence[dict[str, Any]]) -> list[dict
     return out
 
 
+_LANGUAGE_NAME_MAP: dict[str, str] = {
+    "ar": "Arabic",
+    "de": "German",
+    "en": "English",
+    "es": "Spanish",
+    "fr": "French",
+    "hi": "Hindi",
+    "it": "Italian",
+    "ja": "Japanese",
+    "ko": "Korean",
+    "nl": "Dutch",
+    "pl": "Polish",
+    "pt": "Portuguese",
+    "ru": "Russian",
+    "tr": "Turkish",
+    "uk": "Ukrainian",
+    "zh": "Chinese",
+}
+
+_LANGUAGE_CODE_MAP: dict[str, str] = {
+    "eng": "en",
+    "spa": "es",
+    "fra": "fr",
+    "fre": "fr",
+    "deu": "de",
+    "ger": "de",
+    "ita": "it",
+    "por": "pt",
+    "rus": "ru",
+    "ukr": "uk",
+    "jpn": "ja",
+    "kor": "ko",
+    "zho": "zh",
+    "chi": "zh",
+}
+
+_EN_STOPWORDS = {
+    "the",
+    "and",
+    "to",
+    "of",
+    "in",
+    "for",
+    "with",
+    "on",
+    "is",
+    "are",
+    "we",
+    "you",
+    "hello",
+    "thanks",
+    "meeting",
+    "team",
+    "today",
+}
+
+_ES_STOPWORDS = {
+    "el",
+    "la",
+    "los",
+    "las",
+    "de",
+    "que",
+    "y",
+    "en",
+    "para",
+    "con",
+    "es",
+    "somos",
+    "hola",
+    "gracias",
+    "reunion",
+    "equipo",
+    "hoy",
+}
+
+
+def _normalise_language_code(value: object | None) -> str | None:
+    if not isinstance(value, str):
+        return None
+    raw = value.strip().lower()
+    if not raw:
+        return None
+    cleaned = raw.replace("_", "-")
+    base = cleaned.split("-", 1)[0]
+    if not base.isalpha():
+        return None
+    if len(base) == 2:
+        return base
+    if len(base) == 3:
+        return _LANGUAGE_CODE_MAP.get(base, None)
+    return None
+
+
+def _language_name(code: str) -> str:
+    return _LANGUAGE_NAME_MAP.get(code, code.upper())
+
+
+def _guess_language_from_text(text: str) -> str | None:
+    sample = text.strip().lower()
+    if not sample:
+        return None
+    tokens = re.findall(r"[a-zA-Z\u00c0-\u017f]+", sample)
+    if not tokens:
+        return None
+    en_score = sum(1 for token in tokens if token in _EN_STOPWORDS)
+    es_score = sum(1 for token in tokens if token in _ES_STOPWORDS)
+    if any(ch in sample for ch in "áéíóúñ¿¡"):
+        es_score += 2
+    if en_score == 0 and es_score == 0:
+        return None
+    if es_score > en_score:
+        return "es"
+    if en_score > es_score:
+        return "en"
+    return None
+
+
+def _segment_language(
+    segment: dict[str, Any],
+    *,
+    detected_language: str | None,
+    transcript_language_override: str | None,
+) -> str:
+    if transcript_language_override:
+        return transcript_language_override
+    seg_language = _normalise_language_code(segment.get("language"))
+    if seg_language:
+        return seg_language
+    text_language = _guess_language_from_text(str(segment.get("text") or ""))
+    if text_language:
+        return text_language
+    if detected_language:
+        return detected_language
+    return "unknown"
+
+
+def _duration_weight(start: float, end: float, text: str) -> float:
+    duration = max(0.0, end - start)
+    if duration > 0:
+        return duration
+    tokens = max(len(text.split()), 1)
+    return tokens * 0.01
+
+
+def _language_stats(
+    asr_segments: Sequence[dict[str, Any]],
+    *,
+    detected_language: str | None,
+    transcript_language_override: str | None,
+) -> tuple[list[dict[str, Any]], str, dict[str, float], list[dict[str, Any]]]:
+    if not asr_segments:
+        fallback = transcript_language_override or detected_language or "unknown"
+        return [], fallback, {}, []
+
+    enriched = sorted(
+        (dict(seg) for seg in asr_segments),
+        key=lambda row: (
+            _safe_float(row.get("start"), default=0.0),
+            _safe_float(row.get("end"), default=0.0),
+        ),
+    )
+
+    weighted_totals: dict[str, float] = {}
+    spans: list[dict[str, Any]] = []
+    for segment in enriched:
+        start = _safe_float(segment.get("start"), default=0.0)
+        end = _safe_float(segment.get("end"), default=start)
+        if end < start:
+            end = start
+        text = str(segment.get("text") or "").strip()
+        lang = _segment_language(
+            segment,
+            detected_language=detected_language,
+            transcript_language_override=transcript_language_override,
+        )
+        segment["language"] = lang
+
+        weight = _duration_weight(start, end, text)
+        weighted_totals[lang] = weighted_totals.get(lang, 0.0) + weight
+
+        if spans and spans[-1]["lang"] == lang and start <= _safe_float(spans[-1]["end"]) + 0.5:
+            spans[-1]["end"] = round(max(_safe_float(spans[-1]["end"]), end), 3)
+        else:
+            spans.append(
+                {
+                    "start": round(start, 3),
+                    "end": round(end, 3),
+                    "lang": lang,
+                }
+            )
+
+    ordered = sorted(weighted_totals.items(), key=lambda row: (-row[1], row[0]))
+    dominant = "unknown"
+    for lang, _weight in ordered:
+        if lang != "unknown":
+            dominant = lang
+            break
+    if dominant == "unknown" and ordered:
+        dominant = ordered[0][0]
+
+    total_weight = sum(weighted_totals.values())
+    distribution: dict[str, float] = {}
+    if total_weight > 0:
+        for lang, weight in ordered:
+            distribution[lang] = round((weight / total_weight) * 100.0, 2)
+
+    return enriched, dominant, distribution, spans
+
+
+def _resolve_target_summary_language(
+    requested_language: str | None,
+    *,
+    dominant_language: str,
+    detected_language: str | None,
+) -> str:
+    requested = _normalise_language_code(requested_language)
+    if requested:
+        return requested
+    if dominant_language and dominant_language != "unknown":
+        return dominant_language
+    if detected_language:
+        return detected_language
+    return "en"
+
+
+def build_summary_prompts(clean_text: str, target_summary_language: str) -> tuple[str, str]:
+    language_name = _language_name(target_summary_language)
+    sys_prompt = (
+        "You are an assistant who writes concise 5-8 bullet summaries of any audio transcript. "
+        f"Write the summary in {language_name}. "
+        "Return only the list without extra explanation."
+    )
+    user_prompt = f"{sys_prompt}\n\nTRANSCRIPT:\n{clean_text}\n\nSUMMARY:"
+    return sys_prompt, user_prompt
+
+
 def _language_payload(info: dict[str, Any]) -> dict[str, Any]:
-    detected = str(
+    detected_raw = str(
         info.get("language")
         or info.get("detected_language")
         or info.get("lang")
         or "unknown"
     )
+    detected = _normalise_language_code(detected_raw) or "unknown"
     confidence_raw = None
     for key in (
         "language_probability",
@@ -708,6 +947,8 @@ async def run_pipeline(
     diariser: Diariser,
     recording_id: str | None = None,
     precheck: PrecheckResult | None = None,
+    target_summary_language: str | None = None,
+    transcript_language_override: str | None = None,
 ) -> TranscriptResult:
     """Transcribe ``audio_path`` and return a structured result."""
     start = time.perf_counter()
@@ -720,6 +961,14 @@ async def run_pipeline(
     stage_raw_audio(audio_path, artifact_paths.raw_audio_path)
 
     precheck_result = precheck or run_precheck(audio_path, cfg)
+    normalized_transcript_language_override = _normalise_language_code(
+        transcript_language_override
+    )
+    resolved_summary_language = _resolve_target_summary_language(
+        target_summary_language,
+        dominant_language=normalized_transcript_language_override or "unknown",
+        detected_language=None,
+    )
 
     atomic_write_json(
         artifact_paths.metrics_json_path,
@@ -742,6 +991,11 @@ async def run_pipeline(
             {
                 "recording_id": artifact_paths.recording_id,
                 "language": {"detected": "unknown", "confidence": None},
+                "dominant_language": normalized_transcript_language_override or "unknown",
+                "language_distribution": {},
+                "language_spans": [],
+                "target_summary_language": resolved_summary_language,
+                "transcript_language_override": normalized_transcript_language_override,
                 "segments": [],
                 "speakers": [],
                 "text": "",
@@ -840,7 +1094,28 @@ async def run_pipeline(
 
         asr_segments = _normalise_asr_segments(raw_segments)
         language_info = _language_payload(info)
-        detected_language = language_info["detected"] if language_info["detected"] != "unknown" else None
+        detected_language = (
+            _normalise_language_code(language_info["detected"])
+            if language_info["detected"] != "unknown"
+            else None
+        )
+        (
+            asr_segments,
+            dominant_language,
+            language_distribution,
+            language_spans,
+        ) = _language_stats(
+            asr_segments,
+            detected_language=detected_language,
+            transcript_language_override=normalized_transcript_language_override,
+        )
+        if language_info["detected"] == "unknown" and dominant_language != "unknown":
+            language_info["detected"] = dominant_language
+        resolved_summary_language = _resolve_target_summary_language(
+            target_summary_language,
+            dominant_language=dominant_language,
+            detected_language=detected_language,
+        )
 
         asr_text = " ".join(seg.get("text", "").strip() for seg in asr_segments).strip()
         clean_text = normalizer.dedup(asr_text)
@@ -854,7 +1129,7 @@ async def run_pipeline(
         speaker_turns = _build_speaker_turns(
             asr_segments,
             diar_segments,
-            default_language=detected_language,
+            default_language=dominant_language if dominant_language != "unknown" else detected_language,
         )
 
         aliases = _load_aliases(cfg.speaker_db)
@@ -875,6 +1150,11 @@ async def run_pipeline(
             {
                 "recording_id": artifact_paths.recording_id,
                 "language": language_info,
+                "dominant_language": dominant_language,
+                "language_distribution": language_distribution,
+                "language_spans": language_spans,
+                "target_summary_language": resolved_summary_language,
+                "transcript_language_override": normalized_transcript_language_override,
                 "segments": asr_segments,
                 "speakers": sorted({aliases.get(row["speaker"], row["speaker"]) for row in diar_segments}),
                 "text": "",
@@ -887,6 +1167,7 @@ async def run_pipeline(
             {
                 "friendly": 0,
                 "model": cfg.llm_model,
+                "target_summary_language": resolved_summary_language,
                 "summary": "No speech detected",
             },
         )
@@ -932,11 +1213,10 @@ async def run_pipeline(
     speaker_lines = _merge_similar(speaker_lines, cfg.merge_similar)
 
     friendly = _sentiment_score(clean_text)
-    sys_prompt = (
-        "You are an assistant who writes concise 5-8 bullet summaries of any audio transcript. "
-        "Return only the list without extra explanation."
+    sys_prompt, user_prompt = build_summary_prompts(
+        clean_text,
+        resolved_summary_language,
     )
-    user_prompt = f"{sys_prompt}\n\nTRANSCRIPT:\n{clean_text}\n\nSUMMARY:"
 
     try:
         msg = await llm.generate(
@@ -961,6 +1241,11 @@ async def run_pipeline(
             {
                 "recording_id": artifact_paths.recording_id,
                 "language": language_info,
+                "dominant_language": dominant_language,
+                "language_distribution": language_distribution,
+                "language_spans": language_spans,
+                "target_summary_language": resolved_summary_language,
+                "transcript_language_override": normalized_transcript_language_override,
                 "segments": asr_segments,
                 "speaker_lines": speaker_lines,
                 "speakers": sorted(set(aliases.get(turn["speaker"], turn["speaker"]) for turn in speaker_turns)),
@@ -974,6 +1259,7 @@ async def run_pipeline(
             {
                 "friendly": friendly,
                 "model": cfg.llm_model,
+                "target_summary_language": resolved_summary_language,
                 "summary": summary,
             },
         )
@@ -1029,4 +1315,5 @@ __all__ = [
     "Settings",
     "Diariser",
     "refresh_aliases",
+    "build_summary_prompts",
 ]
diff --git a/tasks/QUEUE.md b/tasks/QUEUE.md
index eadd3da..378c539 100644
--- a/tasks/QUEUE.md
+++ b/tasks/QUEUE.md
@@ -52,7 +52,7 @@ Queue (in order)
 - Depends on: PR-GDRIVE-INGEST-01 and PR-REFRACTOR-CORE-01 and PR-DB-QUEUE-01
 
 9) PR-LANG-01: Multi-language support (2 languages): language spans, dominant language, UI override + reprocess hooks
-- Status: TODO
+- Status: DONE
 - Tasks file: tasks/PR-LANG-01.md
 - Depends on: PR-PIPELINE-01
 
diff --git a/tests/test_pipeline.py b/tests/test_pipeline.py
index 962db07..9bc1f11 100644
--- a/tests/test_pipeline.py
+++ b/tests/test_pipeline.py
@@ -409,6 +409,104 @@ async def test_pipeline_writes_required_artifacts(tmp_path: Path, mocker):
     assert len(result.unknown_chunks) >= 2
 
 
+@pytest.mark.asyncio
+@respx.mock
+async def test_pipeline_writes_language_spans_for_mixed_language_segments(tmp_path: Path, mocker):
+    mocker.patch(
+        "whisperx.transcribe",
+        return_value=(
+            [
+                {"start": 0.0, "end": 4.0, "text": "hello team and thanks"},
+                {"start": 4.0, "end": 12.0, "text": "hola equipo y gracias por venir"},
+            ],
+            {"language": "en", "language_probability": 0.91},
+        ),
+    )
+    mocker.patch(
+        "transformers.pipeline",
+        lambda *a, **k: lambda text: [{"label": "positive", "score": 0.6}],
+    )
+    respx.post("http://llm:8000/v1/chat/completions").mock(
+        return_value=httpx.Response(
+            200,
+            json={"choices": [{"message": {"content": "- summary"}}]},
+        ),
+    )
+
+    cfg = pipeline.Settings(
+        speaker_db=tmp_path / "db.yaml",
+        tmp_root=tmp_path,
+        recordings_root=tmp_path / "recordings",
+    )
+    await pipeline.run_pipeline(
+        audio_path=fake_audio(tmp_path, "mixed.mp3"),
+        cfg=cfg,
+        llm=llm_client.LLMClient(),
+        diariser=TwoSpeakerDiariser(),
+        recording_id="rec-mixed-lang-1",
+        precheck=precheck_ok(),
+    )
+
+    derived = cfg.recordings_root / "rec-mixed-lang-1" / "derived"
+    transcript_data = json.loads((derived / "transcript.json").read_text(encoding="utf-8"))
+    assert transcript_data["dominant_language"] == "es"
+    assert set(transcript_data["language_distribution"]).issuperset({"en", "es"})
+    assert len(transcript_data["language_spans"]) >= 2
+    assert transcript_data["language_spans"][0]["lang"] == "en"
+    assert transcript_data["language_spans"][1]["lang"] == "es"
+
+
+@pytest.mark.asyncio
+async def test_pipeline_summary_language_override_changes_prompt(tmp_path: Path, mocker):
+    mocker.patch(
+        "whisperx.transcribe",
+        return_value=(
+            [{"start": 0.0, "end": 1.0, "text": "hello team today."}],
+            {"language": "en", "language_probability": 0.9},
+        ),
+    )
+    mocker.patch(
+        "transformers.pipeline",
+        lambda *a, **k: lambda text: [{"label": "positive", "score": 0.6}],
+    )
+
+    captured: dict[str, str] = {}
+
+    async def _fake_generate(
+        self,
+        system_prompt: str,
+        user_prompt: str,
+        model: str | None = None,
+    ):
+        captured["system"] = system_prompt
+        return {"content": "- resumen"}
+
+    mocker.patch.object(llm_client.LLMClient, "generate", _fake_generate)
+
+    cfg = pipeline.Settings(
+        speaker_db=tmp_path / "db.yaml",
+        tmp_root=tmp_path,
+        recordings_root=tmp_path / "recordings",
+    )
+    await pipeline.run_pipeline(
+        audio_path=fake_audio(tmp_path, "summary-lang.mp3"),
+        cfg=cfg,
+        llm=llm_client.LLMClient(),
+        diariser=DummyDiariser(),
+        recording_id="rec-summary-lang-1",
+        precheck=precheck_ok(),
+        target_summary_language="es",
+    )
+
+    assert "Write the summary in Spanish." in captured["system"]
+    summary_data = json.loads(
+        (cfg.recordings_root / "rec-summary-lang-1" / "derived" / "summary.json").read_text(
+            encoding="utf-8"
+        )
+    )
+    assert summary_data["target_summary_language"] == "es"
+
+
 @pytest.mark.asyncio
 @respx.mock
 async def test_pipeline_accepts_pyannote_triplet_itertracks(tmp_path: Path, mocker):
diff --git a/tests/test_ui_routes.py b/tests/test_ui_routes.py
index adbfddf..e3007fe 100644
--- a/tests/test_ui_routes.py
+++ b/tests/test_ui_routes.py
@@ -2,6 +2,7 @@
 
 from __future__ import annotations
 
+import json
 from pathlib import Path
 
 import pytest
@@ -14,6 +15,7 @@ from lan_app.db import (
     create_recording,
     create_project,
     create_voice_profile,
+    get_recording,
     init_db,
     list_projects,
     list_voice_profiles,
@@ -150,12 +152,49 @@ def test_recording_detail_calendar_tab(seeded_client):
 
 
 def test_recording_detail_placeholder_tabs(seeded_client):
-    for tab in ("project", "speakers", "language", "metrics"):
+    for tab in ("project", "speakers", "metrics"):
         r = seeded_client.get(f"/recordings/rec-ui-1?tab={tab}")
         assert r.status_code == 200
         assert "placeholder" in r.text.lower() or "available after" in r.text.lower()
 
 
+def test_recording_detail_language_tab_renders_spans(tmp_path, monkeypatch):
+    cfg = _cfg(tmp_path)
+    monkeypatch.setattr(api, "_settings", cfg)
+    monkeypatch.setattr(ui_routes, "_settings", cfg)
+    init_db(cfg)
+    create_recording(
+        "rec-lang-tab-1",
+        source="drive",
+        source_filename="lang.mp3",
+        status=RECORDING_STATUS_READY,
+        settings=cfg,
+    )
+    derived = cfg.recordings_root / "rec-lang-tab-1" / "derived"
+    derived.mkdir(parents=True, exist_ok=True)
+    (derived / "transcript.json").write_text(
+        json.dumps(
+            {
+                "text": "hello hola",
+                "language": {"detected": "en", "confidence": 0.9},
+                "dominant_language": "es",
+                "language_distribution": {"en": 40.0, "es": 60.0},
+                "language_spans": [
+                    {"start": 0.0, "end": 1.0, "lang": "en"},
+                    {"start": 1.0, "end": 2.0, "lang": "es"},
+                ],
+            }
+        ),
+        encoding="utf-8",
+    )
+    c = TestClient(api.app, follow_redirects=True)
+    r = c.get("/recordings/rec-lang-tab-1?tab=language")
+    assert r.status_code == 200
+    assert "Language Distribution" in r.text
+    assert "Language Spans" in r.text
+    assert "Re-summarize (LLM only)" in r.text
+
+
 def test_recording_detail_not_found(client):
     r = client.get("/recordings/nonexistent-id")
     assert r.status_code == 404
@@ -377,6 +416,108 @@ def test_ui_action_requeue_failure_returns_503(tmp_path, monkeypatch):
     assert "redis down" in r.text
 
 
+def test_ui_language_resummarize_uses_target_language_override(tmp_path, monkeypatch):
+    cfg = _cfg(tmp_path)
+    monkeypatch.setattr(api, "_settings", cfg)
+    monkeypatch.setattr(ui_routes, "_settings", cfg)
+    init_db(cfg)
+    create_recording(
+        "rec-lang-rsum-1",
+        source="drive",
+        source_filename="lang.mp3",
+        status=RECORDING_STATUS_READY,
+        settings=cfg,
+    )
+
+    derived = cfg.recordings_root / "rec-lang-rsum-1" / "derived"
+    derived.mkdir(parents=True, exist_ok=True)
+    (derived / "transcript.json").write_text(
+        json.dumps(
+            {
+                "text": "hello team and hola equipo",
+                "language": {"detected": "en", "confidence": 0.9},
+                "dominant_language": "en",
+                "language_distribution": {"en": 55.0, "es": 45.0},
+                "language_spans": [
+                    {"start": 0.0, "end": 2.0, "lang": "en"},
+                    {"start": 2.0, "end": 4.0, "lang": "es"},
+                ],
+            }
+        ),
+        encoding="utf-8",
+    )
+    (derived / "summary.json").write_text(
+        json.dumps({"friendly": 0, "model": "llama3:8b", "summary": "- old"}),
+        encoding="utf-8",
+    )
+
+    captured: dict[str, str] = {}
+
+    async def _fake_generate(self, system_prompt: str, user_prompt: str, model: str | None = None):
+        captured["system_prompt"] = system_prompt
+        captured["model"] = model or ""
+        return {"content": "- resumen actualizado"}
+
+    monkeypatch.setattr(ui_routes.LLMClient, "generate", _fake_generate)
+    c = TestClient(api.app, follow_redirects=False)
+    r = c.post(
+        "/ui/recordings/rec-lang-rsum-1/language/resummarize",
+        data={
+            "target_summary_language": "es",
+            "transcript_language_override": "en",
+        },
+    )
+    assert r.status_code == 303
+
+    recording = get_recording("rec-lang-rsum-1", settings=cfg)
+    assert recording is not None
+    assert recording["target_summary_language"] == "es"
+    assert recording["language_override"] == "en"
+
+    summary_payload = json.loads((derived / "summary.json").read_text(encoding="utf-8"))
+    assert summary_payload["summary"] == "- resumen actualizado"
+    assert summary_payload["target_summary_language"] == "es"
+    assert "Write the summary in Spanish." in captured["system_prompt"]
+
+
+def test_ui_language_retranscribe_enqueues_precheck_and_saves_overrides(tmp_path, monkeypatch):
+    cfg = _cfg(tmp_path)
+    monkeypatch.setattr(api, "_settings", cfg)
+    monkeypatch.setattr(ui_routes, "_settings", cfg)
+    init_db(cfg)
+    create_recording(
+        "rec-lang-rtr-1",
+        source="drive",
+        source_filename="lang.mp3",
+        status=RECORDING_STATUS_READY,
+        settings=cfg,
+    )
+    called: dict[str, str] = {}
+
+    def _fake_enqueue(recording_id: str, *, settings=None, job_type=JOB_TYPE_PRECHECK):
+        called["recording_id"] = recording_id
+        called["job_type"] = job_type
+        return None
+
+    monkeypatch.setattr(ui_routes, "enqueue_recording_job", _fake_enqueue)
+    c = TestClient(api.app, follow_redirects=False)
+    r = c.post(
+        "/ui/recordings/rec-lang-rtr-1/language/retranscribe",
+        data={
+            "target_summary_language": "es",
+            "transcript_language_override": "en",
+        },
+    )
+    assert r.status_code == 303
+    assert called["recording_id"] == "rec-lang-rtr-1"
+    assert called["job_type"] == JOB_TYPE_PRECHECK
+
+    recording = get_recording("rec-lang-rtr-1", settings=cfg)
+    assert recording is not None
+    assert recording["target_summary_language"] == "es"
+    assert recording["language_override"] == "en"
+
+
 def test_ui_action_delete_purge_failure_returns_503(tmp_path, monkeypatch):
     cfg = _cfg(tmp_path)
     monkeypatch.setattr(api, "_settings", cfg)
