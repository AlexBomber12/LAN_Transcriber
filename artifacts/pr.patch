diff --git a/lan_transcriber/pipeline.py b/lan_transcriber/pipeline.py
index 0e48b06..7c32e38 100644
--- a/lan_transcriber/pipeline.py
+++ b/lan_transcriber/pipeline.py
@@ -392,10 +392,41 @@ _QUESTION_TYPE_KEYS = (
 )
 
 
-def _truncate_for_prompt(text: str, *, max_chars: int = 500) -> str:
-    if len(text) <= max_chars:
-        return text
-    return f"{text[: max_chars - 3].rstrip()}..."
+def _chunk_text_for_prompt(text: str, *, max_chars: int = 500) -> list[str]:
+    normalized = " ".join(text.split())
+    if not normalized:
+        return []
+    if len(normalized) <= max_chars:
+        return [normalized]
+
+    chunks: list[str] = []
+    words = normalized.split(" ")
+    current: list[str] = []
+    current_len = 0
+
+    for word in words:
+        word_len = len(word)
+        if not current:
+            if word_len > max_chars:
+                for start in range(0, word_len, max_chars):
+                    chunks.append(word[start : start + max_chars])
+                continue
+            current = [word]
+            current_len = word_len
+            continue
+
+        next_len = current_len + 1 + word_len
+        if next_len > max_chars:
+            chunks.append(" ".join(current))
+            current = [word]
+            current_len = word_len
+        else:
+            current.append(word)
+            current_len = next_len
+
+    if current:
+        chunks.append(" ".join(current))
+    return chunks
 
 
 def _normalise_prompt_speaker_turns(
@@ -405,21 +436,22 @@ def _normalise_prompt_speaker_turns(
 ) -> list[dict[str, Any]]:
     out: list[dict[str, Any]] = []
     for row in speaker_turns:
-        if len(out) >= max_turns:
-            break
-        text = _truncate_for_prompt(str(row.get("text") or "").strip())
-        if not text:
-            continue
-        payload: dict[str, Any] = {
-            "start": round(_safe_float(row.get("start"), default=0.0), 3),
-            "end": round(_safe_float(row.get("end"), default=0.0), 3),
-            "speaker": str(row.get("speaker") or "S1"),
-            "text": text,
-        }
+        start = round(_safe_float(row.get("start"), default=0.0), 3)
+        end = round(_safe_float(row.get("end"), default=0.0), 3)
+        speaker = str(row.get("speaker") or "S1")
         lang = _normalise_language_code(row.get("language"))
-        if lang:
-            payload["language"] = lang
-        out.append(payload)
+        for chunk in _chunk_text_for_prompt(str(row.get("text") or "").strip()):
+            if len(out) >= max_turns:
+                return out
+            payload: dict[str, Any] = {
+                "start": start,
+                "end": end,
+                "speaker": speaker,
+                "text": chunk,
+            }
+            if lang:
+                payload["language"] = lang
+            out.append(payload)
     return out
 
 
diff --git a/tests/test_pipeline.py b/tests/test_pipeline.py
index 71aa492..8a67340 100644
--- a/tests/test_pipeline.py
+++ b/tests/test_pipeline.py
@@ -539,6 +539,28 @@ def test_build_summary_payload_prefers_parsed_summary_field():
     assert payload["summary"] == "- one\n- two"
 
 
+def test_build_structured_summary_prompts_preserves_long_turn_text():
+    long_text = " ".join(f"word{i}" for i in range(300))
+    expected = " ".join(long_text.split())
+    _system_prompt, user_prompt = pipeline.build_structured_summary_prompts(
+        [
+            {
+                "start": 0.0,
+                "end": 120.0,
+                "speaker": "S1",
+                "text": long_text,
+                "language": "en",
+            }
+        ],
+        "en",
+    )
+    payload = json.loads(user_prompt)
+    turns = payload["speaker_turns"]
+    assert len(turns) > 1
+    reconstructed = " ".join(str(turn["text"]) for turn in turns)
+    assert reconstructed == expected
+
+
 @pytest.mark.asyncio
 async def test_pipeline_writes_structured_summary_payload(tmp_path: Path, mocker):
     mocker.patch(
