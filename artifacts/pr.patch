diff --git a/lan_transcriber/pipeline.py b/lan_transcriber/pipeline.py
index 5910e0f..aac7412 100644
--- a/lan_transcriber/pipeline.py
+++ b/lan_transcriber/pipeline.py
@@ -786,54 +786,95 @@ async def run_pipeline(
             segments=[],
         )
 
-    import whisperx
-
-    def _asr() -> tuple[list[dict[str, Any]], dict[str, Any]]:
-        kwargs: dict[str, Any] = {"vad_filter": True, "language": "auto"}
-        try:
-            segments, info = whisperx.transcribe(
-                str(audio_path),
-                word_timestamps=True,
-                **kwargs,
-            )
-        except TypeError:
-            segments, info = whisperx.transcribe(str(audio_path), **kwargs)
-        return list(segments), dict(info or {})
-
-    async def _safe_diarise() -> Any:
-        try:
-            return await diariser(audio_path)
-        except Exception:
-            return _fallback_diarization(precheck_result.duration_sec)
-
-    asr_task = asyncio.to_thread(_asr)
-    diar_task = _safe_diarise()
-    (raw_segments, info), diarization = await asyncio.gather(asr_task, diar_task)
-
-    asr_segments = _normalise_asr_segments(raw_segments)
-    language_info = _language_payload(info)
-    detected_language = language_info["detected"] if language_info["detected"] != "unknown" else None
-
-    asr_text = " ".join(seg.get("text", "").strip() for seg in asr_segments).strip()
-    clean_text = normalizer.dedup(asr_text)
-    diar_segments = _safe_diarization_segments(diarization)
-    if not diar_segments and asr_segments:
-        fallback_end = max(_safe_float(seg.get("end")) for seg in asr_segments)
-        diar_segments = [
-            {"start": 0.0, "end": round(max(fallback_end, 0.1), 3), "speaker": "S1"}
-        ]
+    def _write_failed_artifacts(
+        exc: Exception,
+        *,
+        friendly_score: int = 0,
+        language_payload: dict[str, Any] | None = None,
+        asr_count: int = 0,
+        diar_count: int = 0,
+        speaker_turn_count: int = 0,
+    ) -> None:
+        atomic_write_json(
+            artifact_paths.summary_json_path,
+            {
+                "friendly": friendly_score,
+                "model": cfg.llm_model,
+                "summary": "",
+                "status": "failed",
+            },
+        )
+        atomic_write_json(
+            artifact_paths.metrics_json_path,
+            {
+                "status": "failed",
+                "version": 1,
+                "precheck": {
+                    "duration_sec": precheck_result.duration_sec,
+                    "speech_ratio": precheck_result.speech_ratio,
+                    "quarantine_reason": None,
+                },
+                "language": language_payload or {"detected": "unknown", "confidence": None},
+                "asr_segments": asr_count,
+                "diar_segments": diar_count,
+                "speaker_turns": speaker_turn_count,
+                "error": str(exc) or exc.__class__.__name__,
+            },
+        )
 
-    speaker_turns = _build_speaker_turns(
-        asr_segments,
-        diar_segments,
-        default_language=detected_language,
-    )
+    try:
+        import whisperx
+
+        def _asr() -> tuple[list[dict[str, Any]], dict[str, Any]]:
+            kwargs: dict[str, Any] = {"vad_filter": True, "language": "auto"}
+            try:
+                segments, info = whisperx.transcribe(
+                    str(audio_path),
+                    word_timestamps=True,
+                    **kwargs,
+                )
+            except TypeError:
+                segments, info = whisperx.transcribe(str(audio_path), **kwargs)
+            return list(segments), dict(info or {})
+
+        async def _safe_diarise() -> Any:
+            try:
+                return await diariser(audio_path)
+            except Exception:
+                return _fallback_diarization(precheck_result.duration_sec)
+
+        asr_task = asyncio.to_thread(_asr)
+        diar_task = _safe_diarise()
+        (raw_segments, info), diarization = await asyncio.gather(asr_task, diar_task)
+
+        asr_segments = _normalise_asr_segments(raw_segments)
+        language_info = _language_payload(info)
+        detected_language = language_info["detected"] if language_info["detected"] != "unknown" else None
+
+        asr_text = " ".join(seg.get("text", "").strip() for seg in asr_segments).strip()
+        clean_text = normalizer.dedup(asr_text)
+        diar_segments = _safe_diarization_segments(diarization)
+        if not diar_segments and asr_segments:
+            fallback_end = max(_safe_float(seg.get("end")) for seg in asr_segments)
+            diar_segments = [
+                {"start": 0.0, "end": round(max(fallback_end, 0.1), 3), "speaker": "S1"}
+            ]
 
-    aliases = _load_aliases(cfg.speaker_db)
-    for row in diar_segments:
-        label = str(row["speaker"])
-        aliases.setdefault(label, label)
-    _save_aliases(aliases, cfg.speaker_db)
+        speaker_turns = _build_speaker_turns(
+            asr_segments,
+            diar_segments,
+            default_language=detected_language,
+        )
+
+        aliases = _load_aliases(cfg.speaker_db)
+        for row in diar_segments:
+            label = str(row["speaker"])
+            aliases.setdefault(label, label)
+        _save_aliases(aliases, cfg.speaker_db)
+    except Exception as exc:
+        error_rate_total.inc()
+        _write_failed_artifacts(exc)
+        raise
 
     if not clean_text:
         _clear_dir(artifact_paths.snippets_dir)
@@ -975,31 +1016,13 @@ async def run_pipeline(
         )
     except Exception as exc:
         error_rate_total.inc()
-        atomic_write_json(
-            artifact_paths.summary_json_path,
-            {
-                "friendly": friendly,
-                "model": cfg.llm_model,
-                "summary": "",
-                "status": "failed",
-            },
-        )
-        atomic_write_json(
-            artifact_paths.metrics_json_path,
-            {
-                "status": "failed",
-                "version": 1,
-                "precheck": {
-                    "duration_sec": precheck_result.duration_sec,
-                    "speech_ratio": precheck_result.speech_ratio,
-                    "quarantine_reason": None,
-                },
-                "language": language_info,
-                "asr_segments": len(asr_segments),
-                "diar_segments": len(diar_segments),
-                "speaker_turns": len(speaker_turns),
-                "error": str(exc) or exc.__class__.__name__,
-            },
+        _write_failed_artifacts(
+            exc,
+            friendly_score=friendly,
+            language_payload=language_info,
+            asr_count=len(asr_segments),
+            diar_count=len(diar_segments),
+            speaker_turn_count=len(speaker_turns),
         )
         raise
     finally:
diff --git a/tests/test_pipeline.py b/tests/test_pipeline.py
index 4709f03..882c52b 100644
--- a/tests/test_pipeline.py
+++ b/tests/test_pipeline.py
@@ -619,6 +619,41 @@ async def test_pipeline_error_marks_metrics_failed(tmp_path: Path, mocker):
     assert metrics_data["error"] == "llm boom"
 
 
+@pytest.mark.asyncio
+async def test_pipeline_pre_llm_error_marks_metrics_failed(tmp_path: Path, mocker):
+    mocker.patch("whisperx.transcribe", side_effect=RuntimeError("asr boom"))
+
+    cfg = pipeline.Settings(
+        speaker_db=tmp_path / "db.yaml",
+        tmp_root=tmp_path,
+        recordings_root=tmp_path / "recordings",
+    )
+    audio = wav_audio(
+        tmp_path,
+        name="asr-fail.wav",
+        duration_sec=24.0,
+        speech=True,
+    )
+
+    with pytest.raises(RuntimeError, match="asr boom"):
+        await pipeline.run_pipeline(
+            audio_path=audio,
+            cfg=cfg,
+            llm=llm_client.LLMClient(),
+            diariser=DummyDiariser(),
+            recording_id="rec-asr-fail-1",
+            precheck=precheck_ok(),
+        )
+
+    derived = cfg.recordings_root / "rec-asr-fail-1" / "derived"
+    summary_data = json.loads((derived / "summary.json").read_text(encoding="utf-8"))
+    metrics_data = json.loads((derived / "metrics.json").read_text(encoding="utf-8"))
+
+    assert summary_data["status"] == "failed"
+    assert metrics_data["status"] == "failed"
+    assert metrics_data["error"] == "asr boom"
+
+
 def test_run_precheck_quarantine_rules(tmp_path: Path):
     cfg = pipeline.Settings(
         speaker_db=tmp_path / "db.yaml",
