diff --git a/lan_app/db.py b/lan_app/db.py
index 5f8720f..f60dcb0 100644
--- a/lan_app/db.py
+++ b/lan_app/db.py
@@ -228,28 +228,16 @@ _MIGRATIONS: tuple[str, ...] = (
     WHERE project_id IS NOT NULL AND project_assignment_source IS NULL;
     """,
     """
-    WITH candidate_recordings AS (
-        SELECT recording_id
-        FROM jobs
-        WHERE type IN ('stt', 'diarize', 'align', 'language', 'llm', 'metrics')
-          AND status = 'queued'
-          AND started_at IS NULL
-          AND finished_at IS NULL
-        GROUP BY recording_id
-        HAVING COUNT(DISTINCT type) = 6
-    ),
-    placeholder_rows AS (
-        SELECT MIN(rowid) AS row_id
-        FROM jobs
-        WHERE recording_id IN (SELECT recording_id FROM candidate_recordings)
-          AND type IN ('stt', 'diarize', 'align', 'language', 'llm', 'metrics')
-          AND status = 'queued'
-          AND started_at IS NULL
-          AND finished_at IS NULL
-        GROUP BY recording_id, type
-    )
     DELETE FROM jobs
-    WHERE rowid IN (SELECT row_id FROM placeholder_rows);
+    WHERE type IN ('stt', 'diarize', 'align', 'language', 'llm', 'metrics')
+      AND status = 'queued'
+      AND started_at IS NULL
+      AND finished_at IS NULL
+      AND created_at = (
+          SELECT recordings.created_at
+          FROM recordings
+          WHERE recordings.id = jobs.recording_id
+      );
     """,
 )
 
diff --git a/lan_app/worker_tasks.py b/lan_app/worker_tasks.py
index 9b9abbc..43940d5 100644
--- a/lan_app/worker_tasks.py
+++ b/lan_app/worker_tasks.py
@@ -78,22 +78,31 @@ def _restore_status_from_precheck_log(
     except OSError:
         return None, None
 
+    restored_status: str | None = None
     quarantine_reason: str | None = None
     for line in reversed(lines):
         if quarantine_reason is None:
             reason_match = _QUARANTINE_REASON_RE.search(line)
             if reason_match is not None:
                 quarantine_reason = reason_match.group(1).strip() or None
-        status_match = _TERMINAL_STATUS_RE.search(line)
-        if status_match is None:
-            continue
-        status = status_match.group(1).strip()
+        if restored_status is None:
+            status_match = _TERMINAL_STATUS_RE.search(line)
+            if status_match is not None:
+                status = status_match.group(1).strip()
+                if (
+                    status in RECORDING_STATUSES
+                    and status
+                    not in {RECORDING_STATUS_QUEUED, RECORDING_STATUS_PROCESSING}
+                ):
+                    restored_status = status
+                    if restored_status != RECORDING_STATUS_QUARANTINE:
+                        return restored_status, None
         if (
-            status in RECORDING_STATUSES
-            and status not in {RECORDING_STATUS_QUEUED, RECORDING_STATUS_PROCESSING}
+            restored_status == RECORDING_STATUS_QUARANTINE
+            and quarantine_reason is not None
         ):
-            return status, quarantine_reason
-    return None, None
+            return restored_status, quarantine_reason
+    return restored_status, quarantine_reason
 
 
 def _success_status(job_type: str) -> str:
@@ -468,20 +477,21 @@ def process_job(job_id: str, recording_id: str, job_type: str) -> dict[str, str]
                 recording_id,
                 settings,
             )
-            if restored_status is not None:
-                set_recording_status(
-                    recording_id,
-                    restored_status,
-                    settings=settings,
-                    quarantine_reason=restored_quarantine_reason,
-                )
-                _append_step_log(
-                    log_path,
-                    (
-                        "restored recording status from precheck log "
-                        f"after unsupported legacy job: {restored_status}"
-                    ),
-                )
+            if restored_status is None:
+                restored_status = RECORDING_STATUS_FAILED
+            set_recording_status(
+                recording_id,
+                restored_status,
+                settings=settings,
+                quarantine_reason=restored_quarantine_reason,
+            )
+            _append_step_log(
+                log_path,
+                (
+                    "restored recording status after unsupported legacy job: "
+                    f"{restored_status}"
+                ),
+            )
         return {
             "job_id": job_id,
             "recording_id": recording_id,
diff --git a/tests/test_db_queue.py b/tests/test_db_queue.py
index e831261..2cd0f85 100644
--- a/tests/test_db_queue.py
+++ b/tests/test_db_queue.py
@@ -117,22 +117,45 @@ def test_placeholder_cleanup_migration_only_removes_legacy_placeholders(tmp_path
             status=JOB_STATUS_QUEUED,
         )
 
-    # Simulate a real queue-enqueued legacy job for the same recording.
-    create_job(
-        "job-mig-real-extra-stt-1",
-        recording_id="rec-mig-placeholder-1",
-        job_type=JOB_TYPE_STT,
-        settings=cfg,
-        status=JOB_STATUS_QUEUED,
-    )
+    with connect(cfg) as conn:
+        conn.execute(
+            """
+            UPDATE recordings
+            SET created_at = ?, updated_at = ?
+            WHERE id = ?
+            """,
+            ("2020-01-02T00:00:00Z", "2020-01-02T00:00:00Z", "rec-mig-placeholder-1"),
+        )
+        conn.execute(
+            """
+            UPDATE jobs
+            SET created_at = ?, updated_at = ?
+            WHERE recording_id = ?
+            """,
+            ("2020-01-02T00:00:00Z", "2020-01-02T00:00:00Z", "rec-mig-placeholder-1"),
+        )
+        conn.commit()
 
-    create_job(
-        "job-mig-real-queued-stt-1",
-        recording_id="rec-mig-real-queued-1",
-        job_type=JOB_TYPE_STT,
-        settings=cfg,
-        status=JOB_STATUS_QUEUED,
-    )
+    # Simulate a recording where all six legacy jobs were intentionally enqueued later.
+    with connect(cfg) as conn:
+        conn.execute(
+            """
+            UPDATE recordings
+            SET created_at = ?, updated_at = ?
+            WHERE id = ?
+            """,
+            ("2020-01-01T00:00:00Z", "2020-01-01T00:00:00Z", "rec-mig-real-queued-1"),
+        )
+        conn.commit()
+
+    for job_type in placeholder_types:
+        create_job(
+            f"job-mig-real-{job_type}-1",
+            recording_id="rec-mig-real-queued-1",
+            job_type=job_type,
+            settings=cfg,
+            status=JOB_STATUS_QUEUED,
+        )
 
     with connect(cfg) as conn:
         current_version = int(conn.execute("PRAGMA user_version").fetchone()[0])
@@ -144,13 +167,10 @@ def test_placeholder_cleanup_migration_only_removes_legacy_placeholders(tmp_path
     for job_type in placeholder_types:
         assert get_job(f"job-mig-placeholder-{job_type}-1", settings=cfg) is None
 
-    extra_job = get_job("job-mig-real-extra-stt-1", settings=cfg)
-    assert extra_job is not None
-    assert extra_job["status"] == JOB_STATUS_QUEUED
-
-    queued_job = get_job("job-mig-real-queued-stt-1", settings=cfg)
-    assert queued_job is not None
-    assert queued_job["status"] == JOB_STATUS_QUEUED
+    for job_type in placeholder_types:
+        queued_job = get_job(f"job-mig-real-{job_type}-1", settings=cfg)
+        assert queued_job is not None
+        assert queued_job["status"] == JOB_STATUS_QUEUED
 
 
 def test_worker_noop_updates_job_and_recording_state(tmp_path: Path, monkeypatch):
@@ -231,6 +251,84 @@ def test_worker_legacy_job_restores_status_from_precheck_log(tmp_path: Path, mon
     assert "unsupported legacy job type under single-job pipeline" in str(job["error"])
 
 
+def test_worker_legacy_job_restores_quarantine_reason(tmp_path: Path, monkeypatch):
+    cfg = _test_settings(tmp_path)
+    monkeypatch.setenv("LAN_DATA_ROOT", str(cfg.data_root))
+    monkeypatch.setenv("LAN_RECORDINGS_ROOT", str(cfg.recordings_root))
+    monkeypatch.setenv("LAN_DB_PATH", str(cfg.db_path))
+    monkeypatch.setenv("LAN_PROM_SNAPSHOT_PATH", str(cfg.metrics_snapshot_path))
+
+    init_db(cfg)
+    create_recording(
+        "rec-worker-legacy-q-1",
+        source="test",
+        source_filename="legacy-q.mp3",
+        status=RECORDING_STATUS_QUEUED,
+        settings=cfg,
+    )
+    create_job(
+        "job-worker-legacy-q-1",
+        recording_id="rec-worker-legacy-q-1",
+        job_type=JOB_TYPE_STT,
+        settings=cfg,
+    )
+
+    precheck_log = cfg.recordings_root / "rec-worker-legacy-q-1" / "logs" / "step-precheck.log"
+    precheck_log.parent.mkdir(parents=True, exist_ok=True)
+    precheck_log.write_text(
+        (
+            "[2026-02-22T00:00:00Z] quarantined reason=duration_lt_20s\n"
+            "[2026-02-22T00:00:01Z] finished job=job-precheck-q-1 "
+            "type=precheck recording_status=Quarantine\n"
+        ),
+        encoding="utf-8",
+    )
+
+    result = process_job("job-worker-legacy-q-1", "rec-worker-legacy-q-1", JOB_TYPE_STT)
+    recording = get_recording("rec-worker-legacy-q-1", settings=cfg)
+
+    assert result["status"] == "ignored"
+    assert recording is not None
+    assert recording["status"] == RECORDING_STATUS_QUARANTINE
+    assert recording["quarantine_reason"] == "duration_lt_20s"
+
+
+def test_worker_legacy_job_falls_back_to_failed_without_precheck_log(
+    tmp_path: Path, monkeypatch
+):
+    cfg = _test_settings(tmp_path)
+    monkeypatch.setenv("LAN_DATA_ROOT", str(cfg.data_root))
+    monkeypatch.setenv("LAN_RECORDINGS_ROOT", str(cfg.recordings_root))
+    monkeypatch.setenv("LAN_DB_PATH", str(cfg.db_path))
+    monkeypatch.setenv("LAN_PROM_SNAPSHOT_PATH", str(cfg.metrics_snapshot_path))
+
+    init_db(cfg)
+    create_recording(
+        "rec-worker-legacy-fallback-1",
+        source="test",
+        source_filename="legacy-fallback.mp3",
+        status=RECORDING_STATUS_QUEUED,
+        settings=cfg,
+    )
+    create_job(
+        "job-worker-legacy-fallback-1",
+        recording_id="rec-worker-legacy-fallback-1",
+        job_type=JOB_TYPE_STT,
+        settings=cfg,
+    )
+
+    result = process_job(
+        "job-worker-legacy-fallback-1",
+        "rec-worker-legacy-fallback-1",
+        JOB_TYPE_STT,
+    )
+    recording = get_recording("rec-worker-legacy-fallback-1", settings=cfg)
+
+    assert result["status"] == "ignored"
+    assert recording is not None
+    assert recording["status"] == RECORDING_STATUS_FAILED
+
+
 def test_load_calendar_summary_context_uses_preparsed_candidates(tmp_path: Path, monkeypatch):
     cfg = _test_settings(tmp_path)
     monkeypatch.setattr(
