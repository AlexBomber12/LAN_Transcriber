diff --git a/.env.example b/.env.example
index c80834c..71044dc 100644
--- a/.env.example
+++ b/.env.example
@@ -7,17 +7,27 @@ LLM_BASE_URL=http://192.168.0.4:8000
 LLM_API_KEY=
 LLM_MODEL=
 
+# Runtime paths (LAN_ prefixed)
+LAN_DATA_ROOT=/data
+LAN_RECORDINGS_ROOT=/data/recordings
+LAN_SPEAKER_DB=/data/db/speaker_bank.yaml
+LAN_VOICES_DIR=/data/voices
+LAN_UNKNOWN_DIR=/data/recordings/unknown
+LAN_TMP_ROOT=/data/tmp
+LAN_PROM_SNAPSHOT_PATH=/data/metrics.snap
+LAN_DB_PATH=/data/db/app.db
+
 # Plaud fetcher (beta)
 FETCH_INTERVAL_SEC=300
 
-# Prometheus fallback
-PROM_SNAPSHOT_PATH=/data/metrics.snap
-
 # Optional metadata
 TRANSCRIBER_VERSION=local
 TRANSCRIBER_DOCKER_TARGET=runtime-lite
 TRANSCRIBER_PULL_POLICY=never
 LANG_DEFAULT=ru
 
+# Legacy fallback (kept for backwards compatibility)
+# PROM_SNAPSHOT_PATH=/data/metrics.snap
+
 # Optional prebuilt image (if set, also set TRANSCRIBER_PULL_POLICY=always)
 # TRANSCRIBER_IMAGE=ghcr.io/alexbomber12/lan-transcriber:latest
diff --git a/README.md b/README.md
index aa56bcb..40329eb 100644
--- a/README.md
+++ b/README.md
@@ -31,13 +31,29 @@ This produces:
 
 ## Runtime data root
 
-Runtime mutable state must live under `/data` (mounted from `./data` in Docker):
+Runtime mutable state must live under `/data` in containers (mounted from `./data` in Docker):
 
-- `/data/artifacts`
-- `/data/msal`
+- `/data/db/app.db`
+- `/data/db/speaker_bank.yaml`
+- `/data/recordings/<recording_id>/...`
+- `/data/auth/msal_cache.bin`
+- `/data/secrets/gdrive_sa.json`
 - `/data/voices`
-- `/data/db`
-- `/data/logs`
+- `/data/tmp`
+
+Canonical artifact layout (v1):
+
+```text
+/data/recordings/<recording_id>/
+  raw/audio.<ext>
+  derived/transcript.json
+  derived/transcript.txt
+  derived/segments.json
+  derived/snippets/
+  derived/summary.json
+  derived/metrics.json
+  logs/step-*.log
+```
 
 Do not commit secrets or runtime-generated state files.
 
@@ -83,7 +99,8 @@ future monitoring.
 
 ## Speaker alias API
 
-POST `/alias/{speaker_id}` with JSON `{"alias": "Alice"}` updates `speaker_bank.yaml`. Delete the file to reset aliases.
+POST `/alias/{speaker_id}` with JSON `{"alias": "Alice"}` updates
+`/data/db/speaker_bank.yaml` (or `LAN_SPEAKER_DB` if overridden).
 
 
 ![demo](docs/demo.gif)
diff --git a/data/.gitignore b/data/.gitignore
index 3012384..44d1926 100644
--- a/data/.gitignore
+++ b/data/.gitignore
@@ -6,4 +6,8 @@
 !voices/
 !db/
 !logs/
+!recordings/
+!auth/
+!secrets/
+!tmp/
 !*/.gitkeep
diff --git a/data/README.md b/data/README.md
index 0946049..ae7dd99 100644
--- a/data/README.md
+++ b/data/README.md
@@ -1,14 +1,23 @@
 # Runtime Data Root
 
 `/data` is the runtime state root inside containers. In local development,
-`./data` is mounted to `/data`.
+`./data` is mounted to `/data` through Docker.
 
 Expected subdirectories:
 
-- `artifacts/` - transcripts, summaries, snippets, and derived outputs
-- `msal/` - Microsoft auth token cache files
+- `db/` - SQLite database and speaker alias data (`app.db`, `speaker_bank.yaml`)
+- `recordings/<recording_id>/` - canonical per-recording artifacts:
+  - `raw/audio.<ext>`
+  - `derived/transcript.json`
+  - `derived/transcript.txt`
+  - `derived/segments.json`
+  - `derived/snippets/`
+  - `derived/summary.json`
+  - `derived/metrics.json`
+  - `logs/step-*.log`
+- `auth/` - Microsoft delegated auth token cache (`msal_cache.bin`)
+- `secrets/` - mounted secret files (for example `gdrive_sa.json`)
 - `voices/` - voice samples and profile assets
-- `db/` - SQLite database files and migrations state
-- `logs/` - runtime and job logs
+- `tmp/` - temporary files used during processing
 
 Do not commit secrets or runtime-generated files from this directory.
diff --git a/docker-compose.yml b/docker-compose.yml
index 731b615..c24ef6e 100644
--- a/docker-compose.yml
+++ b/docker-compose.yml
@@ -12,11 +12,18 @@ services:
       - "7860:7860"
     environment:
       - PYTHONPATH=/app
+      - LAN_DATA_ROOT=${LAN_DATA_ROOT:-/data}
+      - LAN_RECORDINGS_ROOT=${LAN_RECORDINGS_ROOT:-/data/recordings}
+      - LAN_SPEAKER_DB=${LAN_SPEAKER_DB:-/data/db/speaker_bank.yaml}
+      - LAN_VOICES_DIR=${LAN_VOICES_DIR:-/data/voices}
+      - LAN_UNKNOWN_DIR=${LAN_UNKNOWN_DIR:-/data/recordings/unknown}
+      - LAN_TMP_ROOT=${LAN_TMP_ROOT:-/data/tmp}
+      - LAN_PROM_SNAPSHOT_PATH=${LAN_PROM_SNAPSHOT_PATH:-/data/metrics.snap}
+      - LAN_DB_PATH=${LAN_DB_PATH:-/data/db/app.db}
       - LLM_BASE_URL=${LLM_BASE_URL}
       - LLM_API_KEY=${LLM_API_KEY}
       - LLM_MODEL=${LLM_MODEL:-}
       - FETCH_INTERVAL_SEC=${FETCH_INTERVAL_SEC:-300}
-      - PROM_SNAPSHOT_PATH=${PROM_SNAPSHOT_PATH:-/data/metrics.snap}
       - TRANSCRIBER_VERSION=${TRANSCRIBER_VERSION:-local}
       - LANG_DEFAULT=${LANG_DEFAULT:-en}
     volumes:
diff --git a/lan_transcriber/__init__.py b/lan_transcriber/__init__.py
index 32770c5..e324364 100644
--- a/lan_transcriber/__init__.py
+++ b/lan_transcriber/__init__.py
@@ -1,6 +1,13 @@
 """LAN Transcriber package."""
 
 from .aliases import ALIAS_PATH, load_aliases, save_aliases
+from .artifacts import (
+    RecordingArtifacts,
+    atomic_write_json,
+    atomic_write_text,
+    build_recording_artifacts,
+    stage_raw_audio,
+)
 from .llm_client import LLMClient, generate
 from .metrics import (
     error_rate_total,
@@ -16,6 +23,11 @@ __all__ = [
     "ALIAS_PATH",
     "load_aliases",
     "save_aliases",
+    "RecordingArtifacts",
+    "build_recording_artifacts",
+    "stage_raw_audio",
+    "atomic_write_text",
+    "atomic_write_json",
     "LLMClient",
     "generate",
     "p95_latency_seconds",
diff --git a/lan_transcriber/aliases.py b/lan_transcriber/aliases.py
index 8fba3ac..d9b7243 100644
--- a/lan_transcriber/aliases.py
+++ b/lan_transcriber/aliases.py
@@ -1,17 +1,20 @@
 from __future__ import annotations
 
+import os
 from pathlib import Path
 from typing import Dict
 
 import yaml
 
-ALIAS_PATH = Path(__file__).resolve().parent / "speaker_bank.yaml"
+from .runtime_paths import default_alias_path
+
+ALIAS_PATH = Path(os.getenv("LAN_SPEAKER_DB", str(default_alias_path())))
 
 
 def load_aliases(path: Path = ALIAS_PATH) -> Dict[str, str]:
     """Load speaker aliases from ``path`` if it exists."""
     if path.exists():
-        data = yaml.safe_load(path.read_text())
+        data = yaml.safe_load(path.read_text(encoding="utf-8"))
         if isinstance(data, dict):
             return {str(k): str(v) for k, v in data.items()}
     return {}
@@ -19,7 +22,8 @@ def load_aliases(path: Path = ALIAS_PATH) -> Dict[str, str]:
 
 def save_aliases(aliases: Dict[str, str], path: Path = ALIAS_PATH) -> None:
     """Persist ``aliases`` to ``path`` as YAML."""
-    path.write_text(yaml.safe_dump(dict(sorted(aliases.items()))))
+    path.parent.mkdir(parents=True, exist_ok=True)
+    path.write_text(yaml.safe_dump(dict(sorted(aliases.items()))), encoding="utf-8")
 
 
 __all__ = ["ALIAS_PATH", "load_aliases", "save_aliases"]
diff --git a/lan_transcriber/api.py b/lan_transcriber/api.py
index aaf2b06..cbd0eee 100644
--- a/lan_transcriber/api.py
+++ b/lan_transcriber/api.py
@@ -1,74 +1,5 @@
-from __future__ import annotations
+"""Compatibility wrapper for application API objects."""
 
-import asyncio
-from typing import List
-from fastapi import FastAPI
-from fastapi.responses import StreamingResponse, Response
-from prometheus_client import CONTENT_TYPE_LATEST, generate_latest
-from pathlib import Path
-from .metrics import write_metrics_snapshot
-from pydantic import BaseModel
+from lan_app.api import ALIAS_PATH, app, healthz, set_current_result
 
-from .aliases import load_aliases, save_aliases, ALIAS_PATH
-from .pipeline import refresh_aliases
-from .models import TranscriptResult
-
-app = FastAPI()
-_subscribers: List[asyncio.Queue[str]] = []
-_current_result: TranscriptResult | None = None
-
-
-@app.get("/healthz")
-async def healthz() -> dict[str, str]:
-    """Simple health check used by monitoring."""
-    return {"status": "ok"}
-
-
-@app.on_event("startup")
-async def _start_metrics() -> None:
-    asyncio.create_task(write_metrics_snapshot(Path("metrics.snap")))
-
-
-class AliasUpdate(BaseModel):
-    alias: str
-
-
-@app.post("/alias/{speaker_id}")
-async def update_alias(speaker_id: str, upd: AliasUpdate):
-    aliases = load_aliases(ALIAS_PATH)
-    aliases[speaker_id] = upd.alias
-    save_aliases(aliases, ALIAS_PATH)
-    if _current_result is not None:
-        refresh_aliases(_current_result, ALIAS_PATH)
-    for q in list(_subscribers):
-        q.put_nowait("updated")
-    return {"speaker": speaker_id, "alias": upd.alias}
-
-
-@app.get("/metrics")
-async def metrics() -> Response:
-    return Response(generate_latest(), media_type=CONTENT_TYPE_LATEST)
-
-
-@app.get("/events")
-async def events():
-    q: asyncio.Queue[str] = asyncio.Queue()
-    _subscribers.append(q)
-
-    async def gen():
-        try:
-            while True:
-                await q.get()
-                yield "event: speaker_alias_updated\ndata: updated\n\n"
-        finally:
-            _subscribers.remove(q)
-
-    return StreamingResponse(gen(), media_type="text/event-stream")
-
-
-def set_current_result(result: TranscriptResult | None) -> None:
-    global _current_result
-    _current_result = result
-
-
-__all__ = ["app", "set_current_result", "healthz"]
+__all__ = ["ALIAS_PATH", "app", "set_current_result", "healthz"]
diff --git a/lan_transcriber/pipeline.py b/lan_transcriber/pipeline.py
index ab87689..fd3b260 100644
--- a/lan_transcriber/pipeline.py
+++ b/lan_transcriber/pipeline.py
@@ -1,19 +1,29 @@
 from __future__ import annotations
 
 import asyncio
-import tempfile
 import time
 from pathlib import Path
 from typing import Iterable, List, Protocol
 
-from .aliases import load_aliases as _load_aliases, save_aliases as _save_aliases, ALIAS_PATH
-
 from pydantic_settings import BaseSettings
 
-from .llm_client import LLMClient
-from .models import TranscriptResult, SpeakerSegment
 from . import normalizer
-from .metrics import p95_latency_seconds, error_rate_total
+from .aliases import ALIAS_PATH, load_aliases as _load_aliases, save_aliases as _save_aliases
+from .artifacts import (
+    atomic_write_json,
+    atomic_write_text,
+    build_recording_artifacts,
+    stage_raw_audio,
+)
+from .llm_client import LLMClient
+from .metrics import error_rate_total, p95_latency_seconds
+from .models import SpeakerSegment, TranscriptResult
+from .runtime_paths import (
+    default_recordings_root,
+    default_tmp_root,
+    default_unknown_dir,
+    default_voices_dir,
+)
 
 
 class Diariser(Protocol):
@@ -26,9 +36,10 @@ class Settings(BaseSettings):
     """Runtime configuration for the transcription pipeline."""
 
     speaker_db: Path = ALIAS_PATH
-    voices_dir: Path = Path.home() / "voices"
-    unknown_dir: Path = Path.home() / "unknown_voices"
-    tmp_root: Path = Path(tempfile.gettempdir())
+    recordings_root: Path = default_recordings_root()
+    voices_dir: Path = default_voices_dir()
+    unknown_dir: Path = default_unknown_dir()
+    tmp_root: Path = default_tmp_root()
     llm_model: str = "llama3:8b"
     embed_threshold: float = 0.65
     merge_similar: float = 0.9
@@ -70,13 +81,36 @@ def refresh_aliases(result: TranscriptResult, alias_path: Path = ALIAS_PATH) ->
     result.speakers = sorted({aliases.get(s.speaker, s.speaker) for s in result.segments})
 
 
+def _default_recording_id(audio_path: Path) -> str:
+    stem = audio_path.stem.strip()
+    return stem or "recording"
+
+
 async def run_pipeline(
-    audio_path: Path, cfg: Settings, llm: LLMClient, diariser: Diariser
+    audio_path: Path,
+    cfg: Settings,
+    llm: LLMClient,
+    diariser: Diariser,
+    recording_id: str | None = None,
 ) -> TranscriptResult:
     """Transcribe ``audio_path`` and return a structured result."""
     start = time.perf_counter()
     import whisperx
 
+    artifact_paths = build_recording_artifacts(
+        cfg.recordings_root,
+        recording_id=recording_id or _default_recording_id(audio_path),
+        audio_ext=audio_path.suffix,
+    )
+    stage_raw_audio(audio_path, artifact_paths.raw_audio_path)
+    atomic_write_json(
+        artifact_paths.metrics_json_path,
+        {
+            "status": "placeholder",
+            "version": 1,
+        },
+    )
+
     aliases = _load_aliases(cfg.speaker_db)
 
     def _asr() -> tuple[List[dict], dict]:
@@ -93,7 +127,28 @@ async def run_pipeline(
     asr_text = " ".join(seg.get("text", "").strip() for seg in segments).strip()
     clean_text = normalizer.dedup(asr_text)
     if not clean_text:
-        return TranscriptResult.empty("No speech detected")
+        atomic_write_text(artifact_paths.transcript_txt_path, "")
+        atomic_write_json(artifact_paths.transcript_json_path, {"recording_id": artifact_paths.recording_id, "speakers": [], "text": ""})
+        atomic_write_json(artifact_paths.segments_json_path, [])
+        atomic_write_json(
+            artifact_paths.summary_json_path,
+            {
+                "friendly": 0,
+                "model": cfg.llm_model,
+                "summary": "No speech detected",
+            },
+        )
+        p95_latency_seconds.observe(time.perf_counter() - start)
+        return TranscriptResult(
+            summary="No speech detected",
+            body="",
+            friendly=0,
+            speakers=[],
+            summary_path=artifact_paths.summary_json_path,
+            body_path=artifact_paths.transcript_txt_path,
+            unknown_chunks=[],
+            segments=[],
+        )
 
     lines: List[str] = []
     speakers: List[str] = []
@@ -119,7 +174,6 @@ async def run_pipeline(
     _save_aliases(aliases, cfg.speaker_db)
     lines = _merge_similar(lines, cfg.merge_similar)
     body = clean_text
-
     friendly = _sentiment_score(body)
 
     sys_prompt = (
@@ -133,24 +187,48 @@ async def run_pipeline(
         )
         summary = msg.get("content", "") if isinstance(msg, dict) else str(msg)
 
-        tmp = Path(tempfile.mkdtemp(prefix="trs_", dir=cfg.tmp_root))
-        sum_path = tmp / f"{audio_path.stem}_summary.md"
-        body_path = tmp / f"{audio_path.stem}.md"
-        sum_path.write_text(summary, encoding="utf-8")
-        body_path.write_text(body, encoding="utf-8")
+        serialised_segments = [segment.model_dump() for segment in segs]
+        atomic_write_text(artifact_paths.transcript_txt_path, body)
+        atomic_write_json(
+            artifact_paths.transcript_json_path,
+            {
+                "recording_id": artifact_paths.recording_id,
+                "speaker_lines": lines,
+                "speakers": sorted(set(speakers)),
+                "text": body,
+            },
+        )
+        atomic_write_json(artifact_paths.segments_json_path, serialised_segments)
+        atomic_write_json(
+            artifact_paths.summary_json_path,
+            {
+                "friendly": friendly,
+                "model": cfg.llm_model,
+                "summary": summary,
+            },
+        )
 
         result = TranscriptResult(
             summary=summary,
             body=body,
             friendly=friendly,
             speakers=sorted(set(speakers)),
-            summary_path=sum_path,
-            body_path=body_path,
+            summary_path=artifact_paths.summary_json_path,
+            body_path=artifact_paths.transcript_txt_path,
             unknown_chunks=[],
             segments=segs,
         )
     except Exception:
         error_rate_total.inc()
+        atomic_write_json(
+            artifact_paths.summary_json_path,
+            {
+                "friendly": friendly,
+                "model": cfg.llm_model,
+                "summary": "",
+                "status": "failed",
+            },
+        )
         raise
     finally:
         p95_latency_seconds.observe(time.perf_counter() - start)
diff --git a/pyproject.toml b/pyproject.toml
index 868e113..20151df 100644
--- a/pyproject.toml
+++ b/pyproject.toml
@@ -19,7 +19,7 @@ dependencies = [
 
 [tool.setuptools.packages.find]
 where = ["."]
-include = ["lan_transcriber*"]
+include = ["lan_transcriber*", "lan_app*"]
 
 [tool.coverage.run]
 source = ["lan_transcriber"]
diff --git a/tasks/QUEUE.md b/tasks/QUEUE.md
index be6c89b..01e0be2 100644
--- a/tasks/QUEUE.md
+++ b/tasks/QUEUE.md
@@ -17,7 +17,7 @@ Queue (in order)
 - Depends on: none
 
 2) PR-REFRACTOR-CORE-01: Refactor existing code into a stable core pipeline library and /data-backed state
-- Status: TODO
+- Status: DONE
 - Tasks file: tasks/PR-REFRACTOR-CORE-01.md
 - Depends on: PR-BOOTSTRAP-01
 
diff --git a/tests/test_metrics.py b/tests/test_metrics.py
index 0b21924..2e2e01c 100644
--- a/tests/test_metrics.py
+++ b/tests/test_metrics.py
@@ -39,7 +39,11 @@ async def test_metrics_file(tmp_path: Path, monkeypatch):
     respx.post("http://llm:8000/v1/chat/completions").mock(
         return_value=httpx.Response(200, json={"choices": [{"message": {"content": "ok"}}]})
     )
-    cfg = pipeline.Settings(speaker_db=tmp_path / "db.yaml", tmp_root=tmp_path)
+    cfg = pipeline.Settings(
+        speaker_db=tmp_path / "db.yaml",
+        tmp_root=tmp_path,
+        recordings_root=tmp_path / "recordings",
+    )
     await pipeline.run_pipeline(mp3(tmp_path), cfg, llm_client.LLMClient(), DummyDiariser())
 
     path = tmp_path / "metrics.snap"
diff --git a/tests/test_pipeline.py b/tests/test_pipeline.py
index 2735e36..45cd1e0 100644
--- a/tests/test_pipeline.py
+++ b/tests/test_pipeline.py
@@ -1,5 +1,6 @@
 from pathlib import Path
 from types import ModuleType, SimpleNamespace
+import json
 
 import httpx
 import pytest
@@ -69,13 +70,22 @@ async def test_tripled_dedup(tmp_path: Path, mocker):
         lambda *a, **k: lambda text: [{"label": "positive", "score": 0.8}],
     )
 
-    cfg = pipeline.Settings(speaker_db=tmp_path / "db.yaml", tmp_root=tmp_path)
+    cfg = pipeline.Settings(
+        speaker_db=tmp_path / "db.yaml",
+        tmp_root=tmp_path,
+        recordings_root=tmp_path / "recordings",
+    )
     res = await pipeline.run_pipeline(
         mp3("3_tripled.mp3"), cfg, llm_client.LLMClient(), DummyDiariser()
     )
 
     assert res.body.strip() == "hello world."
     assert res.summary.strip() == "- ok"
+    assert res.summary_path.name == "summary.json"
+    assert res.body_path.name == "transcript.txt"
+    assert res.body_path.read_text(encoding="utf-8") == "hello world."
+    summary_data = json.loads(res.summary_path.read_text(encoding="utf-8"))
+    assert summary_data["summary"] == "- ok"
 
 
 @pytest.mark.asyncio
@@ -97,7 +107,11 @@ async def test_alias_persist(tmp_path: Path, mocker):
     )
     db = tmp_path / "db.yaml"
     db.write_text("S1: Alice\n")
-    cfg = pipeline.Settings(speaker_db=db, tmp_root=tmp_path)
+    cfg = pipeline.Settings(
+        speaker_db=db,
+        tmp_root=tmp_path,
+        recordings_root=tmp_path / "recordings",
+    )
     res = await pipeline.run_pipeline(
         mp3("1_EN.mp3"), cfg, llm_client.LLMClient(), DummyDiariser()
     )
@@ -123,7 +137,11 @@ async def test_white_noise(tmp_path: Path, mocker):
         lambda *a, **k: lambda text: [{"label": "positive", "score": 0.5}],
     )
 
-    cfg = pipeline.Settings(speaker_db=tmp_path / "db.yaml", tmp_root=tmp_path)
+    cfg = pipeline.Settings(
+        speaker_db=tmp_path / "db.yaml",
+        tmp_root=tmp_path,
+        recordings_root=tmp_path / "recordings",
+    )
     res = await pipeline.run_pipeline(
         mp3("4_white_noise.mp3"), cfg, llm_client.LLMClient(), DummyDiariser()
     )
@@ -150,7 +168,11 @@ async def test_no_talk(tmp_path: Path, mocker):
         lambda *a, **k: lambda text: [{"label": "positive", "score": 0.0}],
     )
 
-    cfg = pipeline.Settings(speaker_db=tmp_path / "db.yaml", tmp_root=tmp_path)
+    cfg = pipeline.Settings(
+        speaker_db=tmp_path / "db.yaml",
+        tmp_root=tmp_path,
+        recordings_root=tmp_path / "recordings",
+    )
     res = await pipeline.run_pipeline(
         mp3("5_no_talk.mp3"), cfg, llm_client.LLMClient(), DummyDiariser()
     )
diff --git a/web_transcribe.py b/web_transcribe.py
index 2820da1..c2effb6 100644
--- a/web_transcribe.py
+++ b/web_transcribe.py
@@ -1,167 +1,16 @@
 #!/usr/bin/env python3
-"""Gradio UI wrapper for the LAN transcriber pipeline."""
+"""Compatibility entrypoint for the Gradio UI app."""
 
-import os
-import sys
-import types
-import asyncio
-import tempfile
-from pathlib import Path
+from lan_app.ui import app, demo, enroll_speaker, transcribe, transcribe_and_summarize
 
-try:
-    import httpx  # noqa: F401 - used in LLM client
-except ModuleNotFoundError:  # pragma: no cover - CI stub
-    sys.modules.setdefault("httpx", types.ModuleType("httpx"))
+__all__ = [
+    "app",
+    "demo",
+    "transcribe",
+    "transcribe_and_summarize",
+    "enroll_speaker",
+]
 
-# When running in CI we stub heavy dependencies so the module imports.
-if os.getenv("CI") == "true":  # pragma: no cover - CI stub
-
-    class _Dummy:
-        def __getattr__(self, _name):
-            return _Dummy()
-
-        def __call__(self, *a, **k):
-            return _Dummy()
-
-        def __enter__(self):
-            return self
-
-        def __exit__(self, exc_type, exc, tb):
-            return False
-
-    class _Stub(types.ModuleType):
-        def __getattr__(self, _name):
-            return _Dummy()
-
-    def _fake(mod: str) -> None:
-        sys.modules[mod] = _Stub(mod)
-
-    for mod in (
-        "torch",
-        "torchvision",
-        "torchaudio",
-        "faster_whisper",
-        "pyannote",
-        "pyannote.audio",
-        "pyannote.pipeline",
-        "gradio",
-        "numpy",
-    ):
-        _fake(mod)
-
-from lan_transcriber import llm_client, pipeline
-
-import gradio as gr  # type: ignore
-from pyannote.audio import Pipeline  # type: ignore
-from fastapi import FastAPI  # type: ignore
-from fastapi.responses import HTMLResponse
-import torch  # type: ignore
-
-
-DEVICE = "cuda" if getattr(torch, "cuda", None) and torch.cuda.is_available() else "cpu"
-
-
-def transcribe(audio_path: str):
-    """Run the pipeline and adapt the result for the UI."""
-    diar = Pipeline.from_pretrained("pyannote/speaker-diarization@3.2").to(DEVICE)
-    cfg = pipeline.Settings()
-    result = asyncio.run(
-        pipeline.run_pipeline(Path(audio_path), cfg, llm_client.LLMClient(), diar)
-    )
-    return (
-        f"### Summary  \n{result.summary}\n\n---\n\n",
-        f"### Friendly-score: **{result.friendly}**",
-        result.body,
-        result.summary_path,
-        result.body_path,
-        "\n".join(str(p) for p in result.unknown_chunks) or "—",
-    )
-
-
-async def transcribe_and_summarize(text: str) -> tuple[Path, Path]:
-    """Simpler helper used in tests."""
-    sys_prompt = (
-        "You are an assistant who writes concise 5-8 bullet summaries of any audio transcript. "
-        "Return only the list without extra explanation."
-    )
-    msg = await llm_client.generate(system_prompt=sys_prompt, user_prompt=text)
-    summary = msg.get("content", "") if isinstance(msg, dict) else str(msg)
-    tmp = Path(tempfile.mkdtemp(prefix="trs_"))
-    sum_path = tmp / "summary.md"
-    full_path = tmp / "full.md"
-    sum_path.write_text(summary, encoding="utf-8")
-    full_path.write_text(text, encoding="utf-8")
-    return sum_path, full_path
-
-
-def enroll_speaker(voice_path: str, name: str):
-    """Dummy implementation kept for UI compatibility."""
-    if not voice_path or not name:
-        return "⚠️ Upload voice sample AND type the name first."
-    cfg = pipeline.Settings()
-    cfg.voices_dir.mkdir(exist_ok=True)
-    import shutil
-
-    shutil.copy(voice_path, cfg.voices_dir / f"{name}.wav")
-    return f"✅ Speaker **{name}** added. You can re-run transcription."
-
-
-with gr.Blocks(
-    title="LAN Recording-Transcriber",
-    css=".scroll {max-height: 65vh; overflow-y: auto;}",
-) as demo:  # pragma: no cover - UI glue
-    gr.Markdown(
-        "## LAN Recording-Transcriber  \n_Offline: WhisperX · pyannote · external LLM_"
-    )
-
-    with gr.Row():
-        with gr.Column(scale=1):
-            audio_in = gr.Audio(type="filepath", label="Drop WAV / MP3 here")
-            btn_proc = gr.Button("Process", variant="primary")
-            btn_clear = gr.Button("Clear")
-        with gr.Column(scale=2):
-            out_md = gr.Markdown(label="Summary + friendly-score")
-            out_full = gr.Markdown(label="Full transcript", elem_classes="scroll")
-            file_sum = gr.File(label="Download summary.md")
-            file_md = gr.File(label="Download full.md")
-            unknown = gr.Markdown(label="New voices saved")
-            out_voice = gr.Markdown(label="Unknown speaker chunks")
-
-    with gr.Accordion("Add speaker to database", open=False):
-        with gr.Row():
-            new_voice = gr.Audio(type="filepath", label="Voice sample (~5 sec)")
-            new_name = gr.Textbox(label="Person name")
-        add_btn = gr.Button("Add")
-        add_out = gr.Markdown()
-
-    btn_proc.click(
-        transcribe,
-        audio_in,
-        outputs=[out_md, out_full, file_sum, file_md, unknown, out_voice],
-    )
-    btn_clear.click(
-        lambda: (None,) * 6,
-        None,
-        [audio_in, out_md, out_full, file_sum, file_md, out_voice],
-    )
-    add_btn.click(enroll_speaker, inputs=[new_voice, new_name], outputs=add_out)
-
-    demo.load(lambda: "ready")
-
-app = FastAPI()
-try:  # pragma: no cover - simple mounting logic
-    if hasattr(gr, "mount_gradio_app"):
-        mounted = gr.mount_gradio_app(app, demo, path="/")
-        if isinstance(mounted, FastAPI):
-            app = mounted
-except Exception:
-    pass
-
-if not any(getattr(r, "path", None) == "/" for r in getattr(app, "routes", [])):
-    @app.get("/", response_class=HTMLResponse)
-    async def root() -> str:
-        """Fallback root route for CI runs with stubbed gradio."""
-        return "<html><body>LAN Transcriber</body></html>"
 
 if __name__ == "__main__":
     demo.launch(
diff --git a/data/auth/.gitkeep b/data/auth/.gitkeep
new file mode 100644
index 0000000..e69de29
diff --git a/data/recordings/.gitkeep b/data/recordings/.gitkeep
new file mode 100644
index 0000000..e69de29
diff --git a/data/secrets/.gitkeep b/data/secrets/.gitkeep
new file mode 100644
index 0000000..e69de29
diff --git a/data/tmp/.gitkeep b/data/tmp/.gitkeep
new file mode 100644
index 0000000..e69de29
diff --git a/lan_app/__init__.py b/lan_app/__init__.py
new file mode 100644
index 0000000..54874c9
--- /dev/null
+++ b/lan_app/__init__.py
@@ -0,0 +1,6 @@
+"""Application-layer package for LAN Transcriber."""
+
+from .api import app as api_app
+from .ui import app as ui_app
+
+__all__ = ["api_app", "ui_app"]
diff --git a/lan_app/api.py b/lan_app/api.py
new file mode 100644
index 0000000..ac83e1c
--- /dev/null
+++ b/lan_app/api.py
@@ -0,0 +1,80 @@
+from __future__ import annotations
+
+import asyncio
+from typing import List
+
+from fastapi import FastAPI
+from fastapi.responses import Response, StreamingResponse
+from prometheus_client import CONTENT_TYPE_LATEST, generate_latest
+from pydantic import BaseModel
+
+from lan_transcriber import aliases
+from lan_transcriber.metrics import write_metrics_snapshot
+from lan_transcriber.models import TranscriptResult
+from lan_transcriber.pipeline import refresh_aliases
+
+from .config import AppSettings
+
+app = FastAPI()
+ALIAS_PATH = aliases.ALIAS_PATH
+_subscribers: List[asyncio.Queue[str]] = []
+_current_result: TranscriptResult | None = None
+_settings = AppSettings()
+
+
+@app.get("/healthz")
+async def healthz() -> dict[str, str]:
+    """Simple health check used by monitoring."""
+    return {"status": "ok"}
+
+
+@app.on_event("startup")
+async def _start_metrics() -> None:
+    _settings.metrics_snapshot_path.parent.mkdir(parents=True, exist_ok=True)
+    asyncio.create_task(write_metrics_snapshot(_settings.metrics_snapshot_path))
+
+
+class AliasUpdate(BaseModel):
+    alias: str
+
+
+@app.post("/alias/{speaker_id}")
+async def update_alias(speaker_id: str, upd: AliasUpdate):
+    path = aliases.ALIAS_PATH
+    known = aliases.load_aliases(path)
+    known[speaker_id] = upd.alias
+    aliases.save_aliases(known, path)
+    if _current_result is not None:
+        refresh_aliases(_current_result, path)
+    for queue in list(_subscribers):
+        queue.put_nowait("updated")
+    return {"speaker": speaker_id, "alias": upd.alias}
+
+
+@app.get("/metrics")
+async def metrics() -> Response:
+    return Response(generate_latest(), media_type=CONTENT_TYPE_LATEST)
+
+
+@app.get("/events")
+async def events():
+    queue: asyncio.Queue[str] = asyncio.Queue()
+    _subscribers.append(queue)
+
+    async def gen():
+        try:
+            while True:
+                await queue.get()
+                yield "event: speaker_alias_updated\ndata: updated\n\n"
+        finally:
+            _subscribers.remove(queue)
+
+    return StreamingResponse(gen(), media_type="text/event-stream")
+
+
+def set_current_result(result: TranscriptResult | None) -> None:
+    global _current_result
+    _current_result = result
+
+
+__all__ = ["ALIAS_PATH", "app", "set_current_result", "healthz"]
diff --git a/lan_app/config.py b/lan_app/config.py
new file mode 100644
index 0000000..e90fc5c
--- /dev/null
+++ b/lan_app/config.py
@@ -0,0 +1,29 @@
+from __future__ import annotations
+
+import os
+from pathlib import Path
+
+from pydantic_settings import BaseSettings
+
+from lan_transcriber.runtime_paths import default_data_root
+
+
+def _default_metrics_snapshot_path() -> Path:
+    legacy = os.getenv("PROM_SNAPSHOT_PATH")
+    if legacy:
+        return Path(legacy)
+    return default_data_root() / "metrics.snap"
+
+
+class AppSettings(BaseSettings):
+    """App-layer runtime settings."""
+
+    data_root: Path = default_data_root()
+    metrics_snapshot_path: Path = _default_metrics_snapshot_path()
+    db_path: Path = default_data_root() / "db" / "app.db"
+
+    class Config:
+        env_prefix = "LAN_"
+
+
+__all__ = ["AppSettings"]
diff --git a/lan_app/db.py b/lan_app/db.py
new file mode 100644
index 0000000..d276fd5
--- /dev/null
+++ b/lan_app/db.py
@@ -0,0 +1,22 @@
+from __future__ import annotations
+
+from pathlib import Path
+
+from .config import AppSettings
+
+
+class DBNotReadyError(RuntimeError):
+    """Raised while DB integration is still intentionally stubbed."""
+
+
+def db_path(settings: AppSettings | None = None) -> Path:
+    cfg = settings or AppSettings()
+    return cfg.db_path
+
+
+def connect(_settings: AppSettings | None = None) -> None:
+    """Stub connection hook reserved for PR-DB-QUEUE-01."""
+    raise DBNotReadyError("DB integration is scheduled for PR-DB-QUEUE-01.")
+
+
+__all__ = ["DBNotReadyError", "db_path", "connect"]
diff --git a/lan_app/jobs.py b/lan_app/jobs.py
new file mode 100644
index 0000000..0db8de6
--- /dev/null
+++ b/lan_app/jobs.py
@@ -0,0 +1,15 @@
+from __future__ import annotations
+
+from dataclasses import dataclass
+from pathlib import Path
+
+
+@dataclass(frozen=True)
+class RecordingJob:
+    """In-memory job envelope until DB-backed queue lands."""
+
+    recording_id: str
+    audio_path: Path
+
+
+__all__ = ["RecordingJob"]
diff --git a/lan_app/ui.py b/lan_app/ui.py
new file mode 100644
index 0000000..d37a530
--- /dev/null
+++ b/lan_app/ui.py
@@ -0,0 +1,201 @@
+#!/usr/bin/env python3
+"""Gradio UI wrapper for the LAN transcriber pipeline."""
+
+from __future__ import annotations
+
+import asyncio
+import os
+import shutil
+import sys
+import tempfile
+import types
+from pathlib import Path
+
+try:
+    import httpx  # noqa: F401 - used in LLM client
+except ModuleNotFoundError:  # pragma: no cover - CI stub
+    sys.modules.setdefault("httpx", types.ModuleType("httpx"))
+
+# When running in CI we stub heavy dependencies so the module imports.
+if os.getenv("CI") == "true":  # pragma: no cover - CI stub
+
+    class _Dummy:
+        def __getattr__(self, _name):
+            return _Dummy()
+
+        def __call__(self, *a, **k):
+            return _Dummy()
+
+        def __enter__(self):
+            return self
+
+        def __exit__(self, exc_type, exc, tb):
+            return False
+
+    class _Stub(types.ModuleType):
+        def __getattr__(self, _name):
+            return _Dummy()
+
+    def _fake(mod: str) -> None:
+        sys.modules[mod] = _Stub(mod)
+
+    for mod in (
+        "torch",
+        "torchvision",
+        "torchaudio",
+        "faster_whisper",
+        "pyannote",
+        "pyannote.audio",
+        "pyannote.pipeline",
+        "gradio",
+        "numpy",
+    ):
+        _fake(mod)
+
+import gradio as gr  # type: ignore
+import torch  # type: ignore
+from fastapi import FastAPI  # type: ignore
+from fastapi.responses import HTMLResponse
+from pyannote.audio import Pipeline  # type: ignore
+
+from lan_transcriber import llm_client, pipeline
+
+from .api import set_current_result
+from .workers import process_recording
+
+DEVICE = "cuda" if getattr(torch, "cuda", None) and torch.cuda.is_available() else "cpu"
+
+
+def transcribe(audio_path: str):
+    """Run the pipeline and adapt the result for the UI."""
+    if not audio_path:
+        return (
+            "### Summary\n\n",
+            "### Friendly-score: **0**",
+            None,
+            None,
+            "No processing notes.",
+            "—",
+        )
+
+    diar = Pipeline.from_pretrained("pyannote/speaker-diarization@3.2").to(DEVICE)
+    cfg = pipeline.Settings()
+    cfg.voices_dir.mkdir(parents=True, exist_ok=True)
+    cfg.recordings_root.mkdir(parents=True, exist_ok=True)
+
+    result = asyncio.run(
+        process_recording(
+            audio_path=Path(audio_path),
+            recording_id=Path(audio_path).stem,
+            cfg=cfg,
+            llm_client=llm_client.LLMClient(),
+            diariser=diar,
+        )
+    )
+    set_current_result(result)
+
+    return (
+        f"### Summary\n\n{result.summary}\n",
+        f"### Friendly-score: **{result.friendly}**\n\n{result.body}",
+        result.summary_path,
+        result.body_path,
+        "Artifacts stored under LAN recordings root.",
+        "\n".join(str(p) for p in result.unknown_chunks) or "—",
+    )
+
+
+async def transcribe_and_summarize(text: str) -> tuple[Path, Path]:
+    """Simpler helper used in tests."""
+    sys_prompt = (
+        "You are an assistant who writes concise 5-8 bullet summaries of any audio transcript. "
+        "Return only the list without extra explanation."
+    )
+    msg = await llm_client.generate(system_prompt=sys_prompt, user_prompt=text)
+    summary = msg.get("content", "") if isinstance(msg, dict) else str(msg)
+
+    cfg = pipeline.Settings()
+    cfg.tmp_root.mkdir(parents=True, exist_ok=True)
+    tmp_dir = Path(tempfile.mkdtemp(prefix="trs_", dir=cfg.tmp_root))
+    sum_path = tmp_dir / "summary.md"
+    full_path = tmp_dir / "full.md"
+    sum_path.write_text(summary, encoding="utf-8")
+    full_path.write_text(text, encoding="utf-8")
+    return sum_path, full_path
+
+
+def enroll_speaker(voice_path: str, name: str):
+    """Dummy implementation kept for UI compatibility."""
+    if not voice_path or not name:
+        return "⚠️ Upload voice sample AND type the name first."
+    cfg = pipeline.Settings()
+    cfg.voices_dir.mkdir(parents=True, exist_ok=True)
+
+    shutil.copy(voice_path, cfg.voices_dir / f"{name}.wav")
+    return f"✅ Speaker **{name}** added. You can re-run transcription."
+
+
+with gr.Blocks(
+    title="LAN Recording-Transcriber",
+    css=".scroll {max-height: 65vh; overflow-y: auto;}",
+) as demo:  # pragma: no cover - UI glue
+    gr.Markdown(
+        "## LAN Recording-Transcriber  \n_Offline: WhisperX · pyannote · external LLM_"
+    )
+
+    with gr.Row():
+        with gr.Column(scale=1):
+            audio_in = gr.Audio(type="filepath", label="Drop WAV / MP3 here")
+            btn_proc = gr.Button("Process", variant="primary")
+            btn_clear = gr.Button("Clear")
+        with gr.Column(scale=2):
+            out_md = gr.Markdown(label="Summary")
+            out_full = gr.Markdown(label="Friendly score + transcript", elem_classes="scroll")
+            file_sum = gr.File(label="Download summary.json")
+            file_md = gr.File(label="Download transcript.txt")
+            notes = gr.Markdown(label="Processing notes")
+            out_voice = gr.Markdown(label="Unknown speaker chunks")
+
+    with gr.Accordion("Add speaker to database", open=False):
+        with gr.Row():
+            new_voice = gr.Audio(type="filepath", label="Voice sample (~5 sec)")
+            new_name = gr.Textbox(label="Person name")
+        add_btn = gr.Button("Add")
+        add_out = gr.Markdown()
+
+    btn_proc.click(
+        transcribe,
+        audio_in,
+        outputs=[out_md, out_full, file_sum, file_md, notes, out_voice],
+    )
+    btn_clear.click(
+        lambda: (None, "", "", None, None, "", ""),
+        None,
+        [audio_in, out_md, out_full, file_sum, file_md, notes, out_voice],
+    )
+    add_btn.click(enroll_speaker, inputs=[new_voice, new_name], outputs=add_out)
+
+    demo.load(lambda: "ready")
+
+app = FastAPI()
+try:  # pragma: no cover - simple mounting logic
+    if hasattr(gr, "mount_gradio_app"):
+        mounted = gr.mount_gradio_app(app, demo, path="/")
+        if isinstance(mounted, FastAPI):
+            app = mounted
+except Exception:
+    pass
+
+if not any(getattr(route, "path", None) == "/" for route in getattr(app, "routes", [])):
+
+    @app.get("/", response_class=HTMLResponse)
+    async def root() -> str:
+        """Fallback root route for CI runs with stubbed gradio."""
+        return "<html><body>LAN Transcriber</body></html>"
+
+
+if __name__ == "__main__":
+    demo.launch(
+        server_name="0.0.0.0",
+        server_port=7860,
+        share=False,
+    )
diff --git a/lan_app/workers.py b/lan_app/workers.py
new file mode 100644
index 0000000..a5c2a94
--- /dev/null
+++ b/lan_app/workers.py
@@ -0,0 +1,29 @@
+from __future__ import annotations
+
+from pathlib import Path
+
+from lan_transcriber.llm_client import LLMClient
+from lan_transcriber.models import TranscriptResult
+from lan_transcriber.pipeline import Diariser, Settings, run_pipeline
+
+
+async def process_recording(
+    audio_path: Path,
+    diariser: Diariser,
+    recording_id: str | None = None,
+    cfg: Settings | None = None,
+    llm_client: LLMClient | None = None,
+) -> TranscriptResult:
+    """Run a single recording through the core pipeline."""
+    settings = cfg or Settings()
+    llm = llm_client or LLMClient()
+    return await run_pipeline(
+        audio_path=audio_path,
+        cfg=settings,
+        llm=llm,
+        diariser=diariser,
+        recording_id=recording_id,
+    )
+
+
+__all__ = ["process_recording"]
diff --git a/lan_transcriber/artifacts.py b/lan_transcriber/artifacts.py
new file mode 100644
index 0000000..8358263
--- /dev/null
+++ b/lan_transcriber/artifacts.py
@@ -0,0 +1,118 @@
+from __future__ import annotations
+
+import json
+import os
+import shutil
+import tempfile
+from dataclasses import dataclass
+from pathlib import Path
+from typing import Any
+
+
+@dataclass(frozen=True)
+class RecordingArtifacts:
+    """Canonical v1 artifact layout for a processed recording."""
+
+    recording_id: str
+    root_dir: Path
+    raw_audio_path: Path
+    transcript_json_path: Path
+    transcript_txt_path: Path
+    segments_json_path: Path
+    snippets_dir: Path
+    summary_json_path: Path
+    metrics_json_path: Path
+    logs_dir: Path
+
+
+def _normalize_recording_id(recording_id: str) -> str:
+    slug = "".join(
+        ch if ch.isalnum() or ch in {"-", "_"} else "-" for ch in recording_id.strip()
+    )
+    slug = slug.strip("-_").lower()
+    return slug or "recording"
+
+
+def _normalize_audio_ext(audio_ext: str | None) -> str:
+    if not audio_ext:
+        return ".bin"
+    return audio_ext if audio_ext.startswith(".") else f".{audio_ext}"
+
+
+def build_recording_artifacts(
+    recordings_root: Path,
+    recording_id: str,
+    audio_ext: str | None = None,
+) -> RecordingArtifacts:
+    """Create and return canonical artifact paths for ``recording_id``."""
+    rid = _normalize_recording_id(recording_id)
+    ext = _normalize_audio_ext(audio_ext)
+    root_dir = recordings_root / rid
+    raw_dir = root_dir / "raw"
+    derived_dir = root_dir / "derived"
+    snippets_dir = derived_dir / "snippets"
+    logs_dir = root_dir / "logs"
+
+    for directory in (raw_dir, derived_dir, snippets_dir, logs_dir):
+        directory.mkdir(parents=True, exist_ok=True)
+
+    return RecordingArtifacts(
+        recording_id=rid,
+        root_dir=root_dir,
+        raw_audio_path=raw_dir / f"audio{ext}",
+        transcript_json_path=derived_dir / "transcript.json",
+        transcript_txt_path=derived_dir / "transcript.txt",
+        segments_json_path=derived_dir / "segments.json",
+        snippets_dir=snippets_dir,
+        summary_json_path=derived_dir / "summary.json",
+        metrics_json_path=derived_dir / "metrics.json",
+        logs_dir=logs_dir,
+    )
+
+
+def stage_raw_audio(source: Path, destination: Path) -> Path:
+    """Copy source audio to canonical raw artifact location."""
+    destination.parent.mkdir(parents=True, exist_ok=True)
+    try:
+        if source.exists() and source.resolve() == destination.resolve():
+            return destination
+    except FileNotFoundError:
+        pass
+    shutil.copy2(source, destination)
+    return destination
+
+
+def _atomic_write_bytes(path: Path, payload: bytes) -> None:
+    path.parent.mkdir(parents=True, exist_ok=True)
+    fd, tmp_name = tempfile.mkstemp(
+        prefix=f".{path.name}.",
+        suffix=".tmp",
+        dir=str(path.parent),
+    )
+    try:
+        with os.fdopen(fd, "wb") as handle:
+            handle.write(payload)
+            handle.flush()
+            os.fsync(handle.fileno())
+        os.replace(tmp_name, path)
+    finally:
+        if os.path.exists(tmp_name):
+            os.unlink(tmp_name)
+
+
+def atomic_write_text(path: Path, text: str) -> None:
+    _atomic_write_bytes(path, text.encode("utf-8"))
+
+
+def atomic_write_json(path: Path, data: Any) -> None:
+    payload = json.dumps(data, ensure_ascii=False, indent=2, sort_keys=True)
+    _atomic_write_bytes(path, f"{payload}\n".encode("utf-8"))
+
+
+__all__ = [
+    "RecordingArtifacts",
+    "build_recording_artifacts",
+    "stage_raw_audio",
+    "atomic_write_text",
+    "atomic_write_json",
+]
diff --git a/lan_transcriber/runtime_paths.py b/lan_transcriber/runtime_paths.py
new file mode 100644
index 0000000..bcdac20
--- /dev/null
+++ b/lan_transcriber/runtime_paths.py
@@ -0,0 +1,37 @@
+from __future__ import annotations
+
+import os
+from pathlib import Path
+
+
+def default_data_root() -> Path:
+    """Return runtime data root, preferring /data with local fallback."""
+    configured = os.getenv("LAN_DATA_ROOT")
+    if configured:
+        return Path(configured)
+
+    data_root = Path("/data")
+    if data_root.exists() and os.access(data_root, os.W_OK):
+        return data_root
+    return Path("data")
+
+
+def default_alias_path() -> Path:
+    return default_data_root() / "db" / "speaker_bank.yaml"
+
+
+def default_recordings_root() -> Path:
+    return default_data_root() / "recordings"
+
+
+def default_voices_dir() -> Path:
+    return default_data_root() / "voices"
+
+
+def default_unknown_dir() -> Path:
+    return default_recordings_root() / "unknown"
+
+
+def default_tmp_root() -> Path:
+    return default_data_root() / "tmp"
+
diff --git a/tests/test_artifacts.py b/tests/test_artifacts.py
new file mode 100644
index 0000000..f748a2a
--- /dev/null
+++ b/tests/test_artifacts.py
@@ -0,0 +1,40 @@
+from pathlib import Path
+import json
+
+from lan_transcriber.artifacts import (
+    atomic_write_json,
+    atomic_write_text,
+    build_recording_artifacts,
+    stage_raw_audio,
+)
+
+
+def test_recording_artifact_layout_and_writes(tmp_path: Path) -> None:
+    artifacts = build_recording_artifacts(
+        recordings_root=tmp_path / "recordings",
+        recording_id="Meeting 42",
+        audio_ext=".mp3",
+    )
+
+    src_audio = tmp_path / "src.mp3"
+    src_audio.write_bytes(b"\x00\x01")
+    stage_raw_audio(src_audio, artifacts.raw_audio_path)
+
+    atomic_write_text(artifacts.transcript_txt_path, "hello world")
+    atomic_write_json(artifacts.summary_json_path, {"summary": "- one"})
+    atomic_write_json(artifacts.segments_json_path, [{"speaker": "S1", "text": "hello"}])
+
+    assert artifacts.recording_id == "meeting-42"
+    assert artifacts.raw_audio_path.exists()
+    assert artifacts.transcript_txt_path.read_text(encoding="utf-8") == "hello world"
+    assert json.loads(artifacts.summary_json_path.read_text(encoding="utf-8"))["summary"] == "- one"
+    assert json.loads(artifacts.segments_json_path.read_text(encoding="utf-8"))[0]["speaker"] == "S1"
+
+
+def test_stage_raw_audio_is_noop_when_source_equals_destination(tmp_path: Path) -> None:
+    path = tmp_path / "audio.wav"
+    path.write_bytes(b"abc")
+
+    out = stage_raw_audio(path, path)
+    assert out == path
+    assert path.read_bytes() == b"abc"
diff --git a/tests/test_runtime_paths.py b/tests/test_runtime_paths.py
new file mode 100644
index 0000000..6f2e3aa
--- /dev/null
+++ b/tests/test_runtime_paths.py
@@ -0,0 +1,16 @@
+from pathlib import Path
+
+from lan_transcriber import runtime_paths
+
+
+def test_default_data_root_from_env(monkeypatch, tmp_path: Path) -> None:
+    monkeypatch.setenv("LAN_DATA_ROOT", str(tmp_path))
+    assert runtime_paths.default_data_root() == tmp_path
+    assert runtime_paths.default_alias_path() == tmp_path / "db" / "speaker_bank.yaml"
+    assert runtime_paths.default_recordings_root() == tmp_path / "recordings"
+
+
+def test_default_data_root_fallback(monkeypatch) -> None:
+    monkeypatch.delenv("LAN_DATA_ROOT", raising=False)
+    monkeypatch.setattr(runtime_paths.os, "access", lambda *_args, **_kwargs: False)
+    assert runtime_paths.default_data_root() == Path("data")
