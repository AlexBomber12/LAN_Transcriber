diff --git a/lan_app/worker_tasks.py b/lan_app/worker_tasks.py
index 87da3d5..02b67eb 100644
--- a/lan_app/worker_tasks.py
+++ b/lan_app/worker_tasks.py
@@ -168,6 +168,33 @@ def _job_attempt(job_id: str, settings: AppSettings) -> int:
         return 0
 
 
+def _start_job_or_ignore_stale_execution(
+    *,
+    job_id: str,
+    recording_id: str,
+    job_type: str,
+    settings: AppSettings,
+    log_path: Path,
+) -> bool:
+    if start_job(job_id, settings=settings):
+        return True
+    job_row = get_job(job_id, settings=settings) or {}
+    status = str(job_row.get("status") or "").strip()
+    if status and status != JOB_STATUS_QUEUED:
+        try:
+            _append_step_log(
+                log_path,
+                (
+                    "ignored stale queue execution "
+                    f"job={job_id} type={job_type} status={status}"
+                ),
+            )
+        except OSError:
+            pass
+        return False
+    raise ValueError(f"Job not found: {job_id}")
+
+
 def _retry_delay_seconds(policy: RetryPolicy, attempt: int) -> int:
     if attempt <= 0:
         return 0
@@ -514,8 +541,19 @@ def process_job(job_id: str, recording_id: str, job_type: str) -> dict[str, str]
     if job_type != JOB_TYPE_PRECHECK:
         recording_before = get_recording(recording_id, settings=settings) or {}
         previous_status = str(recording_before.get("status") or "").strip()
-        if not start_job(job_id, settings=settings):
-            raise ValueError(f"Job not found: {job_id}")
+        if not _start_job_or_ignore_stale_execution(
+            job_id=job_id,
+            recording_id=recording_id,
+            job_type=job_type,
+            settings=settings,
+            log_path=log_path,
+        ):
+            return {
+                "job_id": job_id,
+                "recording_id": recording_id,
+                "job_type": job_type,
+                "status": "ignored",
+            }
         unsupported_error = (
             f"unsupported legacy job type under single-job pipeline: {job_type}"
         )
@@ -580,8 +618,19 @@ def process_job(job_id: str, recording_id: str, job_type: str) -> dict[str, str]
 
     while True:
         try:
-            if not start_job(job_id, settings=settings):
-                raise ValueError(f"Job not found: {job_id}")
+            if not _start_job_or_ignore_stale_execution(
+                job_id=job_id,
+                recording_id=recording_id,
+                job_type=job_type,
+                settings=settings,
+                log_path=log_path,
+            ):
+                return {
+                    "job_id": job_id,
+                    "recording_id": recording_id,
+                    "job_type": job_type,
+                    "status": "ignored",
+                }
             attempt = _job_attempt(job_id, settings)
             if attempt > settings.max_job_attempts:
                 raise RuntimeError(_MAX_ATTEMPTS_ERROR)
diff --git a/tests/test_db_queue.py b/tests/test_db_queue.py
index 70c948c..fce8616 100644
--- a/tests/test_db_queue.py
+++ b/tests/test_db_queue.py
@@ -214,6 +214,52 @@ def test_start_job_only_transitions_queued_jobs(tmp_path: Path):
     assert int(failed_job["attempt"]) == 0
 
 
+def test_worker_ignores_stale_execution_for_non_queued_job(tmp_path: Path, monkeypatch):
+    cfg = _test_settings(tmp_path)
+    monkeypatch.setenv("LAN_DATA_ROOT", str(cfg.data_root))
+    monkeypatch.setenv("LAN_RECORDINGS_ROOT", str(cfg.recordings_root))
+    monkeypatch.setenv("LAN_DB_PATH", str(cfg.db_path))
+    monkeypatch.setenv("LAN_PROM_SNAPSHOT_PATH", str(cfg.metrics_snapshot_path))
+
+    init_db(cfg)
+    create_recording(
+        "rec-worker-stale-exec-1",
+        source="test",
+        source_filename="stale-exec.wav",
+        status=RECORDING_STATUS_NEEDS_REVIEW,
+        settings=cfg,
+    )
+    create_job(
+        "job-worker-stale-exec-1",
+        recording_id="rec-worker-stale-exec-1",
+        job_type=JOB_TYPE_PRECHECK,
+        status=JOB_STATUS_FAILED,
+        settings=cfg,
+    )
+
+    result = process_job(
+        "job-worker-stale-exec-1",
+        "rec-worker-stale-exec-1",
+        JOB_TYPE_PRECHECK,
+    )
+
+    job = get_job("job-worker-stale-exec-1", settings=cfg)
+    recording = get_recording("rec-worker-stale-exec-1", settings=cfg)
+    assert result["status"] == "ignored"
+    assert job is not None
+    assert recording is not None
+    assert job["status"] == JOB_STATUS_FAILED
+    assert recording["status"] == RECORDING_STATUS_NEEDS_REVIEW
+    step_log = (
+        cfg.recordings_root
+        / "rec-worker-stale-exec-1"
+        / "logs"
+        / "step-precheck.log"
+    )
+    assert step_log.exists()
+    assert "ignored stale queue execution" in step_log.read_text(encoding="utf-8")
+
+
 def test_worker_noop_updates_job_and_recording_state(tmp_path: Path, monkeypatch):
     cfg = _test_settings(tmp_path)
     monkeypatch.setenv("LAN_DATA_ROOT", str(cfg.data_root))
