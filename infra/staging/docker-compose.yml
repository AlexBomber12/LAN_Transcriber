version: "3.8"
services:
  lan:
    build:
      context: ../..
      dockerfile: Dockerfile
    ports:
      - "7860:7860"
    environment:
      - LLM_BASE_URL=http://llm:8000
    volumes:
      - lan_cache:/root/.cache
      - /opt/lan_cache/hf:/root/.cache/huggingface
    networks:
      - lan_net

  llm:
    image: ghcr.io/open-webui/vllm:0.1
    environment:
      - MODEL=meta-llama/Meta-Llama-3-8B-Instruct
    ports:
      - "8000:8000"
    networks:
      - lan_net

  plaud_fetcher:
    build:
      context: ../../plaud_fetcher
    depends_on:
      - lan
    environment:
      - INGEST_URL=http://lan:7860/api/plaud_ingest
    networks:
      - lan_net

networks:
  lan_net:

volumes:
  lan_cache:
